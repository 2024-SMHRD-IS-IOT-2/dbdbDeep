{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff6d1f61",
   "metadata": {},
   "source": [
    "## 목표\n",
    "- 모델 평가 기준(metrics)과 EarlyStopping monitor 기준 f1_score로 해서 모델의 학습 상황 점검"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "93e5bd1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import librosa\n",
    "# import librosa.display\n",
    "# import IPython.display as ipd\n",
    "# from IPython.display import Audio\n",
    "\n",
    "from random import randint\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import pydub #오디오 파일을 다루는 라이브러리 : 변환 조작 재생 분석 등\n",
    "# import gTTS # 텍스트를 음성으로 변환하는 라이브러리. 나는 당장 쓸 일 없을 듯?\n",
    "\n",
    "# from tqdm import tqdm\n",
    "# import np_utils\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "\n",
    "# import winsound as sd\n",
    "# import glob\n",
    "# import os\n",
    "# import json\n",
    "# import shutil\n",
    "# import sys\n",
    "# import logging\n",
    "# import unicodedata\n",
    "# from shutil import copyfile\n",
    "# import warnings\n",
    "# if not sys.warnoptions:\n",
    "#     warnings.simplefilter(\"ignore\")\n",
    "# warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder,StandardScaler, OneHotEncoder, scale, MinMaxScaler\n",
    "# from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split, KFold, RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.svm import SVC \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import joblib\n",
    "from joblib import dump, load\n",
    "from xgboost import XGBClassifier \n",
    "\n",
    "import keras\n",
    "from keras.callbacks import ReduceLROnPlateau,ModelCheckpoint,EarlyStopping\n",
    "from keras.models import Sequential\n",
    "from tensorflow.keras.layers import InputLayer, Dense, Conv1D, MaxPooling1D, Flatten, Dropout, LSTM\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "# from keras.preprocessing.sequence import pad_sequences\n",
    "# from keras.utils import to_categorical\n",
    "\n",
    "import tensorflow as tf\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "\n",
    "# from transformers import PreTrainedTokenizer\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2da1d5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_csv = pd.read_csv('e:/Data2/csv/train.csv')\n",
    "valid_csv = pd.read_csv('e:/Data2/csv/valid.csv')\n",
    "X = np.load('./features5.npy')\n",
    "y = train_csv.iloc[:,-7:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0afffe5a",
   "metadata": {},
   "source": [
    "### 필요한 함수들 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "04ff2da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def beepError():\n",
    "    fr = 1000    # range : 37 ~ 32767\n",
    "    du = 2000     # 1000 ms ==1second\n",
    "    sd.Beep(fr, du) # winsound.Beep(frequency, duration)\n",
    "def beepSuccess():\n",
    "    fr = 2000    # range : 37 ~ 32767\n",
    "    du = 1000     # 1000 ms ==1second\n",
    "    sd.Beep(fr, du) # winsound.Beep(frequency, duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71027809",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 임베딩 함수 설정\n",
    "class text_embedding():\n",
    "    def __init__(self, model_name):\n",
    "        self.model_name = model_name\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "  \n",
    "    def transform(self, X,raw_label):\n",
    "        embedding_model = SentenceTransformer(self.model_name)\n",
    "        embedding_vec = embedding_model.encode(raw_label)\n",
    "        X_val = np.concatenate((X, embedding_vec), axis = 1)\n",
    "        return X_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0828b5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_model(data):\n",
    "    model=Sequential()\n",
    "    model.add(InputLayer(shape=(data.shape[1],data.shape[2])))\n",
    "    model.add(Conv1D(256, kernel_size=5, strides=1, padding='same', activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_size=5, strides = 2, padding = 'same'))\n",
    "\n",
    "    model.add(Conv1D(256, kernel_size=5, strides=1, padding='same', activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_size=5, strides = 2, padding = 'same'))\n",
    "\n",
    "    model.add(Conv1D(128, kernel_size=5, strides=1, padding='same', activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_size=5, strides = 2, padding = 'same'))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Conv1D(64, kernel_size=5, strides=1, padding='same', activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_size=5, strides = 2, padding = 'same'))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(units=32, activation='relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "    model.add(Dense(units=7, activation='softmax'))\n",
    "    model.compile(optimizer = 'adam' , loss = 'categorical_crossentropy' , metrics = ['accuracy',f1_metric])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d82d3d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# f1 스코어를 쓸 수 있게 만드는 함수\n",
    "# f1 스코어의 결과 타입은 tensor이므로 이걸 변환해 주는 작업 필요.\n",
    "\n",
    "def f1_metric(y_true, y_pred):\n",
    "    y_true = tf.argmax(y_true, axis=1)\n",
    "    y_pred = tf.argmax(y_pred, axis=1)\n",
    "    return tf.py_function(lambda y_true, y_pred: f1_score(y_true, y_pred, average='weighted'), \n",
    "                          [y_true, y_pred], Tout=tf.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "15b0fd8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기본적인 사전 설정\n",
    "rlrp = ReduceLROnPlateau(monitor='loss', factor=0.4, verbose=0, patience=5, min_lr=0.0000001) #learning rate 조절 \n",
    "modelpath = './model/model_{epoch:02d}-{val_accuracy:.4f}.keras'\n",
    "mcp = ModelCheckpoint(\n",
    "    modelpath,     #저장할 모델의 경로\n",
    "  monitor = 'val_f1_metric', #val_acc를 기준으로 전보다 모델이 나아지는 걸 확인\n",
    "  save_best_only = True,    #나아진 결과만 저장\n",
    "#     save_weights_only=True , #이걸 써 줘야 weights.h5로 저장 가능하다.\n",
    "  verbose = 1               #과정을 출력\n",
    ")\n",
    "\n",
    "#전보다 나아지지 않으면 학습중단\n",
    "\n",
    "es = EarlyStopping(\n",
    "    monitor = 'val_f1',\n",
    "    patience = 5      # 전보다 나아지지 않아도 실행할 횟수\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "9284a0b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Arguments `target` and `output` must have the same rank (ndim). Received: target.shape=(None,), output.shape=(None, 7)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[77], line 29\u001b[0m\n\u001b[0;32m     25\u001b[0m y_test \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39margmax(y_test, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     28\u001b[0m model \u001b[38;5;241m=\u001b[39m cnn_model(X_train_scaled)\n\u001b[1;32m---> 29\u001b[0m history\u001b[38;5;241m=\u001b[39mmodel\u001b[38;5;241m.\u001b[39mfit(\n\u001b[0;32m     30\u001b[0m     X_train_scaled, \n\u001b[0;32m     31\u001b[0m     y_train,batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m40\u001b[39m, \n\u001b[0;32m     32\u001b[0m     epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m, \n\u001b[0;32m     33\u001b[0m     validation_data\u001b[38;5;241m=\u001b[39m(X_test_scaled, y_test), \n\u001b[0;32m     34\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39m[rlrp,mcp]\n\u001b[0;32m     35\u001b[0m )\n\u001b[0;32m     36\u001b[0m test_loss, test_acc \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate(X_test_scaled, y_test, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPre-trained Model: \u001b[39m\u001b[38;5;124m\"\u001b[39m, i)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\nn.py:547\u001b[0m, in \u001b[0;36mcategorical_crossentropy\u001b[1;34m(target, output, from_logits, axis)\u001b[0m\n\u001b[0;32m    541\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    542\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mArguments `target` and `output` must be at least rank 1. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    543\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReceived: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    544\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget.shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, output.shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    545\u001b[0m     )\n\u001b[0;32m    546\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(target\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(output\u001b[38;5;241m.\u001b[39mshape):\n\u001b[1;32m--> 547\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    548\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mArguments `target` and `output` must have the same rank \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    549\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(ndim). Received: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    550\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget.shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, output.shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    551\u001b[0m     )\n\u001b[0;32m    552\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m e1, e2 \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(target\u001b[38;5;241m.\u001b[39mshape, output\u001b[38;5;241m.\u001b[39mshape):\n\u001b[0;32m    553\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m e1 \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m e2 \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m e1 \u001b[38;5;241m!=\u001b[39m e2:\n",
      "\u001b[1;31mValueError\u001b[0m: Arguments `target` and `output` must have the same rank (ndim). Received: target.shape=(None,), output.shape=(None, 7)"
     ]
    }
   ],
   "source": [
    "pre_trained_models = [\n",
    "#     'sentence-transformers/xlm-r-100langs-bert-base-nli-stsb-mean-tokens',\n",
    "# 'sentence-transformers/multi-qa-distilbert-cos-v1',\n",
    "'jhgan/ko-sroberta-multitask',\n",
    "# 'all-distilroberta-v1',\n",
    "# 'jhgan/ko-sbert-multitask',\n",
    "# 'all-MiniLM-L12-v2', 'jhgan/ko-sroberta-sts'\n",
    "]\n",
    "y_np = np.array(y)\n",
    "scaler = StandardScaler()\n",
    "\n",
    "for i in pre_trained_models:\n",
    "#     train_txt_embed = text_embedding(model_name = i)\n",
    "#     X_train_embed = train_txt_embed.transform(X,train_csv['발화문'])\n",
    "   \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_train_embed,y_np, random_state=0,  test_size = 0.3, stratify = y_np)\n",
    "\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    X_train_scaled = np.expand_dims(X_train_scaled,axis =1)\n",
    "    X_test_scaled = np.expand_dims(X_test_scaled,axis =1)\n",
    "\n",
    "\n",
    "    model = cnn_model(X_train_scaled)\n",
    "    history=model.fit(\n",
    "        X_train_scaled, \n",
    "        y_train,batch_size=40, \n",
    "        epochs=50, \n",
    "        validation_data=(X_test_scaled, y_test), \n",
    "        callbacks=[rlrp,mcp]\n",
    "    )\n",
    "    test_loss, test_acc = model.evaluate(X_test_scaled, y_test, verbose=0)\n",
    "    print(\"Pre-trained Model: \", i)\n",
    "    print(\"Test Accuracy: \",test_acc)\n",
    "    \n",
    "#결과 \n",
    "#'sentence-transformers/multi-qa-distilbert-cos-v1'로 임베딩한 게 가장 좋다.(약 81.96%)\n",
    "# 'jhgan/ko-sbert-multitask'과 'jhgan/ko-sroberta-sts'도 나름대로 준수\n",
    "# 모델명 : model_06-0.8196.keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0fa48ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
