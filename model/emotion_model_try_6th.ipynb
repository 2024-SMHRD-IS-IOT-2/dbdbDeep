{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1fa25e0d",
   "metadata": {},
   "source": [
    "#### 새로운 시도를 하기 전에 한 번 지금까지 썼던 모델들 다 검토해보기로"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d2e78846",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import librosa\n",
    "# import librosa.display\n",
    "# import IPython.display as ipd\n",
    "# from IPython.display import Audio\n",
    "\n",
    "from random import randint\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import pydub #오디오 파일을 다루는 라이브러리 : 변환 조작 재생 분석 등\n",
    "# import gTTS # 텍스트를 음성으로 변환하는 라이브러리. 나는 당장 쓸 일 없을 듯?\n",
    "\n",
    "# from tqdm import tqdm\n",
    "# import np_utils\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "\n",
    "# import winsound as sd\n",
    "# import glob\n",
    "# import os\n",
    "# import json\n",
    "# import shutil\n",
    "# import sys\n",
    "# import logging\n",
    "# import unicodedata\n",
    "# from shutil import copyfile\n",
    "# import warnings\n",
    "# if not sys.warnoptions:\n",
    "#     warnings.simplefilter(\"ignore\")\n",
    "# warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder,StandardScaler, OneHotEncoder, scale, MinMaxScaler\n",
    "# from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split, KFold, RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import SVC \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from joblib import dump, load\n",
    "from xgboost import XGBClassifier \n",
    "\n",
    "# import keras\n",
    "from keras.callbacks import ReduceLROnPlateau,ModelCheckpoint,EarlyStopping\n",
    "from keras.models import Sequential\n",
    "from tensorflow.keras.layers import InputLayer, Dense, Conv1D, MaxPooling1D, Flatten, Dropout, LSTM\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "# from keras.preprocessing.sequence import pad_sequences\n",
    "# from keras.utils import to_categorical\n",
    "\n",
    "# import tensorflow\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "\n",
    "# from transformers import PreTrainedTokenizer\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cca4528a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_csv = pd.read_csv('e:/Data2/csv/train.csv')\n",
    "valid_csv = pd.read_csv('e:/Data2/csv/valid.csv')\n",
    "X = np.load('./features5.npy')\n",
    "y = train_csv.iloc[:,-7:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd9f81ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기본적인 사전 설정\n",
    "rlrp = ReduceLROnPlateau(monitor='loss', factor=0.4, verbose=0, patience=5, min_lr=0.0000001) #learning rate 조절 \n",
    "modelpath = './model/model_{epoch:02d}-{val_accuracy:.4f}.keras'\n",
    "mcp = ModelCheckpoint(\n",
    "    modelpath,     #저장할 모델의 경로\n",
    "  monitor = 'val_accuracy', #val_acc를 기준으로 전보다 모델이 나아지는 걸 확인\n",
    "  save_best_only = True,    #나아진 결과만 저장\n",
    "#     save_weights_only=True , #이걸 써 줘야 weights.h5로 저장 가능하다.\n",
    "  verbose = 1               #과정을 출력\n",
    ")\n",
    "\n",
    "#전보다 나아지지 않으면 학습중단\n",
    "\n",
    "es = EarlyStopping(\n",
    "    monitor = 'val_accuracy',\n",
    "    patience = 5      # 전보다 나아지지 않아도 실행할 횟수\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "901808d9",
   "metadata": {},
   "source": [
    "### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "26650060",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_model(x_train):\n",
    "    model=Sequential()\n",
    "    model.add(InputLayer(shape=(x_train.shape[1],x_train.shape[2])))\n",
    "    model.add(Conv1D(256, kernel_size=5, strides=1, padding='same', activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_size=5, strides = 2, padding = 'same'))\n",
    "\n",
    "    model.add(Conv1D(256, kernel_size=5, strides=1, padding='same', activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_size=5, strides = 2, padding = 'same'))\n",
    "\n",
    "    model.add(Conv1D(128, kernel_size=5, strides=1, padding='same', activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_size=5, strides = 2, padding = 'same'))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Conv1D(64, kernel_size=5, strides=1, padding='same', activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_size=5, strides = 2, padding = 'same'))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(units=32, activation='relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "    model.add(Dense(units=7, activation='softmax'))\n",
    "    model.compile(optimizer = 'adam' , loss = 'categorical_crossentropy' , metrics = ['accuracy'])\n",
    "\n",
    "    #model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0d158bf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m506/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3592 - loss: 1.6858\n",
      "Epoch 1: val_accuracy did not improve from 0.50614\n",
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - accuracy: 0.3598 - loss: 1.6847 - val_accuracy: 0.4484 - val_loss: 1.5184 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m511/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4484 - loss: 1.5211\n",
      "Epoch 2: val_accuracy did not improve from 0.50614\n",
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.4484 - loss: 1.5210 - val_accuracy: 0.4511 - val_loss: 1.4871 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4584 - loss: 1.4783\n",
      "Epoch 3: val_accuracy did not improve from 0.50614\n",
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.4584 - loss: 1.4783 - val_accuracy: 0.4679 - val_loss: 1.4360 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m511/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4747 - loss: 1.4391\n",
      "Epoch 4: val_accuracy did not improve from 0.50614\n",
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.4747 - loss: 1.4391 - val_accuracy: 0.4754 - val_loss: 1.4141 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m506/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4845 - loss: 1.4210\n",
      "Epoch 5: val_accuracy did not improve from 0.50614\n",
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.4845 - loss: 1.4209 - val_accuracy: 0.4750 - val_loss: 1.4300 - learning_rate: 0.0010\n",
      "Test Accuracy:  0.4749886393547058\n"
     ]
    }
   ],
   "source": [
    "#StandardScaler로 \n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "   \n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, random_state=0,  test_size = 0.3, stratify = y)\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "X_train_scaled = np.expand_dims(X_train_scaled,axis =1)\n",
    "X_test_scaled = np.expand_dims(X_test_scaled,axis =1)\n",
    "\n",
    "\n",
    "model = second_model(X_train_scaled)\n",
    "history=model.fit(X_train_scaled, y_train, batch_size=40, epochs=50, validation_data=(X_test_scaled, y_test), callbacks=[rlrp,mcp,es])\n",
    "\n",
    "test_loss, test_acc = model.evaluate(X_test_scaled, y_test, verbose=0)\n",
    "print(\"Test Accuracy: \",test_acc)\n",
    "\n",
    "# test 결과값 약 47.5%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4874d2c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m508/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3723 - loss: 1.7180\n",
      "Epoch 1: val_accuracy did not improve from 0.50614\n",
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - accuracy: 0.3725 - loss: 1.7175 - val_accuracy: 0.3832 - val_loss: 1.6285 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m513/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3932 - loss: 1.6417\n",
      "Epoch 2: val_accuracy did not improve from 0.50614\n",
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.3932 - loss: 1.6417 - val_accuracy: 0.3830 - val_loss: 1.6234 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m513/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3923 - loss: 1.6229\n",
      "Epoch 3: val_accuracy did not improve from 0.50614\n",
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.3923 - loss: 1.6229 - val_accuracy: 0.4051 - val_loss: 1.5886 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m506/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4002 - loss: 1.5998\n",
      "Epoch 4: val_accuracy did not improve from 0.50614\n",
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.4003 - loss: 1.5998 - val_accuracy: 0.4084 - val_loss: 1.5726 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4009 - loss: 1.6033\n",
      "Epoch 5: val_accuracy did not improve from 0.50614\n",
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.4009 - loss: 1.6033 - val_accuracy: 0.4126 - val_loss: 1.5696 - learning_rate: 0.0010\n",
      "Test Accuracy:  0.412573903799057\n"
     ]
    }
   ],
   "source": [
    "#MinMaxScaler로 \n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "   \n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, random_state=0,  test_size = 0.3, stratify = y)\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "X_train_scaled = np.expand_dims(X_train_scaled,axis =1)\n",
    "X_test_scaled = np.expand_dims(X_test_scaled,axis =1)\n",
    "\n",
    "\n",
    "model = second_model(X_train_scaled)\n",
    "history=model.fit(X_train_scaled, y_train, batch_size=40, epochs=50, validation_data=(X_test_scaled, y_test), callbacks=[rlrp,mcp,es])\n",
    "\n",
    "test_loss, test_acc = model.evaluate(X_test_scaled, y_test, verbose=0)\n",
    "print(\"Test Accuracy: \",test_acc)\n",
    "\n",
    "# test 결과값 약 41.2% : CNN은 StandardScaler로"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d4c9e1",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "caae2b16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train KNN Accuracy: 0.4249378745797398\n",
      "Test KNN Accuracy: 0.3358344702137335\n"
     ]
    }
   ],
   "source": [
    "# Define the parameter grid for the random search\n",
    "X_train, X_test, y_train, y_test = train_test_split(X , train_csv['감정'],random_state=0, stratify = train_csv['감정'], test_size = 0.3)\n",
    "\n",
    "\n",
    "\n",
    "# 레이블 인코딩\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "\n",
    "\n",
    "\n",
    "param_grid = {\n",
    "    'n_neighbors': np.arange(1, 15),  # Number of neighbors\n",
    "    'weights': ['uniform', 'distance'],  # Weight function\n",
    "    'p': [1, 2]  # Power parameter for the Minkowski distance metric\n",
    "}\n",
    "\n",
    "# Create the KNN classifier\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "# Perform the random search\n",
    "random_search_knn = RandomizedSearchCV(\n",
    "    knn, param_distributions=param_grid, n_iter=10, cv=5, random_state=42\n",
    ")\n",
    "random_search_knn.fit(X_train, y_train_encoded)\n",
    "\n",
    "# Evaluate the KNN model with the best parameters on the test set\n",
    "best_knn = random_search_knn.best_estimator_\n",
    "y_pred_knn = best_knn.predict(X_test)\n",
    "test_accuracy_knn = accuracy_score(y_test_encoded, y_pred_knn)\n",
    "\n",
    "# Evaluate the KNN model on the training set\n",
    "y_train_pred_knn = best_knn.predict(X_train)\n",
    "train_accuracy_knn = accuracy_score(y_train_encoded, y_train_pred_knn)\n",
    "\n",
    "print(\"Train KNN Accuracy:\", train_accuracy_knn)\n",
    "print(\"Test KNN Accuracy:\", test_accuracy_knn)\n",
    "\n",
    "\n",
    "#test 결과값 약 33% 나옴"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d55db2f7",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0a48e6",
   "metadata": {},
   "outputs": [],
   "source": [
    " def lstm_model(X_train):\n",
    "    model = Sequential()\n",
    "    model.add(InputLayer(shape=(X_train.shape[1],X_train.shape[2])))\n",
    "    model.add(LSTM(64, return_sequences=True)) \n",
    "    model.add(LSTM(32)) \n",
    "    model.add(Dense(128,activation='relu'))\n",
    "    model.add(Dense(7, activation='softmax'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "706a95bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m466/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3364 - loss: 0.4459\n",
      "Epoch 1: val_accuracy did not improve from 0.50807\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.3378 - loss: 0.4439 - val_accuracy: 0.4231 - val_loss: 0.3430 - learning_rate: 0.0010\n",
      "Epoch 2/30\n",
      "\u001b[1m451/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4331 - loss: 0.3373\n",
      "Epoch 2: val_accuracy did not improve from 0.50807\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.4337 - loss: 0.3371 - val_accuracy: 0.4520 - val_loss: 0.3306 - learning_rate: 0.0010\n",
      "Epoch 3/30\n",
      "\u001b[1m449/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4600 - loss: 0.3245\n",
      "Epoch 3: val_accuracy did not improve from 0.50807\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.4605 - loss: 0.3244 - val_accuracy: 0.4616 - val_loss: 0.3249 - learning_rate: 0.0010\n",
      "Epoch 4/30\n",
      "\u001b[1m455/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4788 - loss: 0.3159\n",
      "Epoch 4: val_accuracy did not improve from 0.50807\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.4790 - loss: 0.3158 - val_accuracy: 0.4757 - val_loss: 0.3203 - learning_rate: 0.0010\n",
      "Epoch 5/30\n",
      "\u001b[1m441/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4907 - loss: 0.3098\n",
      "Epoch 5: val_accuracy did not improve from 0.50807\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.4910 - loss: 0.3098 - val_accuracy: 0.4679 - val_loss: 0.3196 - learning_rate: 0.0010\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0, stratify = y, test_size = 0.3)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled  = scaler.transform(X_test)\n",
    "\n",
    "X_train_scaled = np.expand_dims(X_train_scaled,axis =1)\n",
    "X_test_scaled = np.expand_dims(X_test_scaled,axis =1)\n",
    "\n",
    "model = lstm_model(X_train_scaled)\n",
    "\n",
    "h1 = model.fit(X_train_scaled,y_train,\n",
    "               validation_split = 0.3,\n",
    "               epochs=30,\n",
    "               batch_size=30,callbacks=[rlrp,es,mcp])\n",
    "\n",
    "#test 결과값 약 46.8% 정도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d869132c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m447/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4046 - loss: 0.3499\n",
      "Epoch 1: val_accuracy did not improve from 0.50807\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4044 - loss: 0.3498 - val_accuracy: 0.4174 - val_loss: 0.3453 - learning_rate: 0.0010\n",
      "Epoch 2/30\n",
      "\u001b[1m454/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4147 - loss: 0.3441\n",
      "Epoch 2: val_accuracy did not improve from 0.50807\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.4148 - loss: 0.3440 - val_accuracy: 0.4096 - val_loss: 0.3454 - learning_rate: 0.0010\n",
      "Epoch 3/30\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4193 - loss: 0.3422\n",
      "Epoch 3: val_accuracy did not improve from 0.50807\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.4194 - loss: 0.3421 - val_accuracy: 0.4328 - val_loss: 0.3396 - learning_rate: 0.0010\n",
      "Epoch 4/30\n",
      "\u001b[1m462/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4339 - loss: 0.3357\n",
      "Epoch 4: val_accuracy did not improve from 0.50807\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.4341 - loss: 0.3357 - val_accuracy: 0.4410 - val_loss: 0.3343 - learning_rate: 0.0010\n",
      "Epoch 5/30\n",
      "\u001b[1m448/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4457 - loss: 0.3342\n",
      "Epoch 5: val_accuracy did not improve from 0.50807\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.4456 - loss: 0.3341 - val_accuracy: 0.4296 - val_loss: 0.3359 - learning_rate: 0.0010\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0, stratify = y, test_size = 0.3)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled  = scaler.transform(X_test)\n",
    "\n",
    "X_train_scaled = np.expand_dims(X_train_scaled,axis =1)\n",
    "X_test_scaled = np.expand_dims(X_test_scaled,axis =1)\n",
    "\n",
    "model = lstm_model(X_train_scaled)\n",
    "\n",
    "h1 = model.fit(X_train_scaled,y_train,\n",
    "               validation_split = 0.3,\n",
    "               epochs=30,\n",
    "               batch_size=30,callbacks=[rlrp,es,mcp])\n",
    "\n",
    "#test 결과값 약 42.7% 정도. LSTM은 StandardScaler로"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d309d22d",
   "metadata": {},
   "source": [
    "### SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9c5c0791",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도 : 0.5160300136425648\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train,y_test =train_test_split(X,train_csv['감정'],random_state=5,stratify=train_csv['감정'],test_size=0.3)\n",
    "#MinMAx Scaler을 이용한 특징 벡터 전처리\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# 레이블 인코딩\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "\n",
    "\n",
    "#분류기 커널 설정\n",
    "clf = SVC(C=100, kernel='rbf', probability=True)\n",
    "#분류기 학습\n",
    "clf.fit(X_train_scaled, y_train_encoded )\n",
    "#각 row의 클래스별 확률을 구하기\n",
    "probabilities = clf.predict_proba(X_test_scaled)\n",
    "print(\"첫 번째 샘플의 클래스별 확률:\", probabilities[0])\n",
    "#예측 결과\n",
    "y_pred = clf.predict(X_test_scaled)\n",
    "accuracy = accuracy_score(y_pred, y_test_encoded)\n",
    "    \n",
    "\n",
    "    \n",
    "print(\"정확도 :\", accuracy)\n",
    "\n",
    "#test 결과값 약 51.6% 정도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d778bf03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "첫 번째 샘플의 클래스별 확률: [0.20003447 0.10426802 0.08509696 0.04807575 0.17558152 0.35403075\n",
      " 0.03291253]\n",
      "정확도 : 0.47510231923601637\n"
     ]
    }
   ],
   "source": [
    "#Scaler를 StandardScaler로\n",
    "\n",
    "X_train, X_test, y_train,y_test =train_test_split(X,train_csv['감정'],random_state=5,stratify=train_csv['감정'],test_size=0.3)\n",
    "#StandardScaler을 이용한 특징 벡터 전처리\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# 레이블 인코딩\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "\n",
    "\n",
    "#분류기 커널 설정\n",
    "clf = SVC(C=100, kernel='rbf', probability=True)\n",
    "#분류기 학습\n",
    "clf.fit(X_train_scaled, y_train_encoded )\n",
    "#각 row의 클래스별 확률을 구하기\n",
    "probabilities = clf.predict_proba(X_test_scaled)\n",
    "print(\"첫 번째 샘플의 클래스별 확률:\", probabilities[0])\n",
    "#예측 결과\n",
    "y_pred = clf.predict(X_test_scaled)\n",
    "accuracy = accuracy_score(y_pred, y_test_encoded)\n",
    "    \n",
    "\n",
    "    \n",
    "print(\"정확도 :\", accuracy)\n",
    "\n",
    "#test 결과값 약 47.5% 정도. SVC에서는 MinMaxScaler로"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ed7f2c",
   "metadata": {},
   "source": [
    "### ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "96b9a16c",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\smhrd\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m623/642\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3924 - loss: 1.6399\n",
      "Epoch 1: val_accuracy did not improve from 0.50807\n",
      "\u001b[1m642/642\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.3932 - loss: 1.6378 - val_accuracy: 0.4578 - val_loss: 1.4724 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "\u001b[1m616/642\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4463 - loss: 1.4941\n",
      "Epoch 2: val_accuracy did not improve from 0.50807\n",
      "\u001b[1m642/642\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4465 - loss: 1.4937 - val_accuracy: 0.4773 - val_loss: 1.4357 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "\u001b[1m630/642\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4760 - loss: 1.4297\n",
      "Epoch 3: val_accuracy did not improve from 0.50807\n",
      "\u001b[1m642/642\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4758 - loss: 1.4300 - val_accuracy: 0.4717 - val_loss: 1.4341 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "\u001b[1m641/642\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4723 - loss: 1.4235\n",
      "Epoch 4: val_accuracy did not improve from 0.50807\n",
      "\u001b[1m642/642\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4723 - loss: 1.4234 - val_accuracy: 0.4765 - val_loss: 1.4274 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "\u001b[1m611/642\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4825 - loss: 1.3928\n",
      "Epoch 5: val_accuracy did not improve from 0.50807\n",
      "\u001b[1m642/642\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4823 - loss: 1.3934 - val_accuracy: 0.4724 - val_loss: 1.4182 - learning_rate: 0.0010\n",
      "\u001b[1m275/275\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 853us/step\n",
      "Training accuracy: 0.4784388244152069\n",
      "Validation accuracy: 0.4723738133907318\n",
      "Test accuracy: 0.3993860845839018\n"
     ]
    }
   ],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,y,random_state=5,stratify=y,test_size=0.3)\n",
    "\n",
    "scaler =StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "# Define the model architecture\n",
    "model = Sequential()\n",
    "model.add(Dense(units=256, activation='relu', input_dim=X_train.shape[1]))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(units=256, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(units=256, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(units=256, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(units=7, activation='softmax'))  # Adjusted to use np.unique for flexibility\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Fit the model\n",
    "history = model.fit(X_train_scaled, y_train, epochs=100, batch_size=32, verbose=1, validation_data=(X_test_scaled, y_test),callbacks=[rlrp,mcp,es])\n",
    "\n",
    "# Retrieve training and validation accuracy\n",
    "train_accuracy = history.history['accuracy'][-1]  # Last epoch accuracy\n",
    "val_accuracy = history.history['val_accuracy'][-1]  # Last epoch validation accuracy\n",
    "\n",
    "# Predict on test set\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "# 임계값 설정\n",
    "threshold = 0.3\n",
    "\n",
    "# 확률이 임계값보다 크면 1로, 작으면 0으로 분류\n",
    "y_pred_labels = (y_pred > threshold).astype(int)\n",
    "# y_pred_labels = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Calculate test accuracy\n",
    "test_accuracy = accuracy_score(y_test, y_pred_labels)\n",
    "\n",
    "# Print accuracies\n",
    "print('Training accuracy:', train_accuracy)\n",
    "print('Validation accuracy:', val_accuracy)\n",
    "print('Test accuracy:', test_accuracy)\n",
    "\n",
    "#test 결과값 약 39.9%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5dd38658",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\smhrd\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m640/642\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3816 - loss: 1.6601\n",
      "Epoch 1: val_accuracy did not improve from 0.50807\n",
      "\u001b[1m642/642\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.3816 - loss: 1.6600 - val_accuracy: 0.4048 - val_loss: 1.6065 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "\u001b[1m629/642\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4023 - loss: 1.5928\n",
      "Epoch 2: val_accuracy did not improve from 0.50807\n",
      "\u001b[1m642/642\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4023 - loss: 1.5928 - val_accuracy: 0.3906 - val_loss: 1.6358 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "\u001b[1m625/642\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4080 - loss: 1.5766\n",
      "Epoch 3: val_accuracy did not improve from 0.50807\n",
      "\u001b[1m642/642\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4081 - loss: 1.5765 - val_accuracy: 0.4173 - val_loss: 1.5588 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "\u001b[1m626/642\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4138 - loss: 1.5649\n",
      "Epoch 4: val_accuracy did not improve from 0.50807\n",
      "\u001b[1m642/642\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4139 - loss: 1.5647 - val_accuracy: 0.4361 - val_loss: 1.5239 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "\u001b[1m628/642\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4236 - loss: 1.5524\n",
      "Epoch 5: val_accuracy did not improve from 0.50807\n",
      "\u001b[1m642/642\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4236 - loss: 1.5522 - val_accuracy: 0.4212 - val_loss: 1.5416 - learning_rate: 0.0010\n",
      "\u001b[1m275/275\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 892us/step\n",
      "Training accuracy: 0.4235248267650604\n",
      "Validation accuracy: 0.42121419310569763\n",
      "Test accuracy: 0.3848340154615734\n"
     ]
    }
   ],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,y,random_state=5,stratify=y,test_size=0.3)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "scaler.fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "# Define the model architecture\n",
    "model = Sequential()\n",
    "model.add(Dense(units=256, activation='relu', input_dim=X_train.shape[1]))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(units=256, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(units=256, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(units=256, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(units=7, activation='softmax'))  # Adjusted to use np.unique for flexibility\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Fit the model\n",
    "history = model.fit(X_train_scaled, y_train, epochs=100, batch_size=32, verbose=1, validation_data=(X_test_scaled, y_test),callbacks=[rlrp,mcp,es])\n",
    "\n",
    "# Retrieve training and validation accuracy\n",
    "train_accuracy = history.history['accuracy'][-1]  # Last epoch accuracy\n",
    "val_accuracy = history.history['val_accuracy'][-1]  # Last epoch validation accuracy\n",
    "\n",
    "# Predict on test set\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "# 임계값 설정\n",
    "threshold = 0.3\n",
    "\n",
    "# 확률이 임계값보다 크면 1로, 작으면 0으로 분류\n",
    "y_pred_labels = (y_pred > threshold).astype(int)\n",
    "# y_pred_labels = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Calculate test accuracy\n",
    "test_accuracy = accuracy_score(y_test, y_pred_labels)\n",
    "\n",
    "# Print accuracies\n",
    "print('Training accuracy:', train_accuracy)\n",
    "print('Validation accuracy:', val_accuracy)\n",
    "print('Test accuracy:', test_accuracy)\n",
    "\n",
    "#test 결과값 약 38.4% 큰 차이는 아니지만 StandardScaler 성능이 더 좋다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1422cf33",
   "metadata": {},
   "source": [
    "### Xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "682bc86e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.29\n"
     ]
    }
   ],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,y,random_state=5,stratify=y,test_size=0.3)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "xgb = XGBClassifier(n_estimators=1000, learning_rate=0.05) #1000개의 가지? epoch? , 0.05 학습률\n",
    "xgb.fit(X_train_scaled, y_train) #학습\n",
    "\n",
    "y_preds = xgb.predict(X_test_scaled) #검증\n",
    "\n",
    "print('Accuracy: %.2f' % accuracy_score(y_test,y_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f027b0",
   "metadata": {},
   "source": [
    "### 확인 결과\n",
    "- CNN, LSTM, SVC의 성능이 괜찮은 것으로 보임\n",
    "- 이제 이걸 텍스트 모델과 결합하는 형태로 실행해 보자.\n",
    "- CNN은 StandardScaler,LSTM은 StandardScaler,SVC에서는 MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bb71a5bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 임베딩 함수 설정\n",
    "class text_embedding():\n",
    "    def __init__(self, model_name):\n",
    "        self.model_name = model_name\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "  \n",
    "    def transform(self, X):\n",
    "        embedding_model = SentenceTransformer(self.model_name)\n",
    "        embedding_vec = embedding_model.encode(train_csv['발화문'])\n",
    "        X_val = np.concatenate((X, embedding_vec), axis = 1)\n",
    "        return X_val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d7abf8",
   "metadata": {},
   "source": [
    "### CNN 모델(텍스트 임베딩)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21609b6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\smhrd\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m512/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5671 - loss: 1.2032\n",
      "Epoch 1: val_accuracy improved from 0.50807 to 0.72465, saving model to ./model/model_01-0.7246.keras\n",
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - accuracy: 0.5676 - loss: 1.2021 - val_accuracy: 0.7246 - val_loss: 0.7837 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m512/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7173 - loss: 0.8205\n",
      "Epoch 2: val_accuracy improved from 0.72465 to 0.73499, saving model to ./model/model_02-0.7350.keras\n",
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 19ms/step - accuracy: 0.7174 - loss: 0.8203 - val_accuracy: 0.7350 - val_loss: 0.7375 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m513/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7594 - loss: 0.6963\n",
      "Epoch 3: val_accuracy improved from 0.73499 to 0.74761, saving model to ./model/model_03-0.7476.keras\n",
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 19ms/step - accuracy: 0.7594 - loss: 0.6962 - val_accuracy: 0.7476 - val_loss: 0.7252 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7756 - loss: 0.6646\n",
      "Epoch 4: val_accuracy improved from 0.74761 to 0.76626, saving model to ./model/model_04-0.7663.keras\n",
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - accuracy: 0.7756 - loss: 0.6645 - val_accuracy: 0.7663 - val_loss: 0.6704 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7899 - loss: 0.5941\n",
      "Epoch 5: val_accuracy improved from 0.76626 to 0.76648, saving model to ./model/model_05-0.7665.keras\n",
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - accuracy: 0.7898 - loss: 0.5942 - val_accuracy: 0.7665 - val_loss: 0.7073 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7995 - loss: 0.5721\n",
      "Epoch 6: val_accuracy improved from 0.76648 to 0.76864, saving model to ./model/model_06-0.7686.keras\n",
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - accuracy: 0.7995 - loss: 0.5721 - val_accuracy: 0.7686 - val_loss: 0.6905 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8098 - loss: 0.5308\n",
      "Epoch 7: val_accuracy did not improve from 0.76864\n",
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - accuracy: 0.8098 - loss: 0.5308 - val_accuracy: 0.7656 - val_loss: 0.7138 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m513/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8166 - loss: 0.5233\n",
      "Epoch 8: val_accuracy did not improve from 0.76864\n",
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - accuracy: 0.8166 - loss: 0.5233 - val_accuracy: 0.7685 - val_loss: 0.6966 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8243 - loss: 0.4769\n",
      "Epoch 9: val_accuracy improved from 0.76864 to 0.77240, saving model to ./model/model_09-0.7724.keras\n",
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 19ms/step - accuracy: 0.8243 - loss: 0.4769 - val_accuracy: 0.7724 - val_loss: 0.6920 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8304 - loss: 0.4609\n",
      "Epoch 10: val_accuracy improved from 0.77240 to 0.77501, saving model to ./model/model_10-0.7750.keras\n",
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - accuracy: 0.8304 - loss: 0.4609 - val_accuracy: 0.7750 - val_loss: 0.6837 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m512/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8371 - loss: 0.4448\n",
      "Epoch 11: val_accuracy did not improve from 0.77501\n",
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - accuracy: 0.8371 - loss: 0.4449 - val_accuracy: 0.7659 - val_loss: 0.6952 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8460 - loss: 0.4285\n",
      "Epoch 12: val_accuracy did not improve from 0.77501\n",
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - accuracy: 0.8460 - loss: 0.4285 - val_accuracy: 0.7627 - val_loss: 0.7453 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m513/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8503 - loss: 0.4139\n",
      "Epoch 13: val_accuracy improved from 0.77501 to 0.77513, saving model to ./model/model_13-0.7751.keras\n",
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - accuracy: 0.8503 - loss: 0.4139 - val_accuracy: 0.7751 - val_loss: 0.7482 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8522 - loss: 0.3910\n",
      "Epoch 14: val_accuracy improved from 0.77513 to 0.77967, saving model to ./model/model_14-0.7797.keras\n",
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - accuracy: 0.8522 - loss: 0.3911 - val_accuracy: 0.7797 - val_loss: 0.7405 - learning_rate: 0.0010\n",
      "Epoch 15/50\n",
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8612 - loss: 0.3767\n",
      "Epoch 15: val_accuracy improved from 0.77967 to 0.78217, saving model to ./model/model_15-0.7822.keras\n",
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - accuracy: 0.8612 - loss: 0.3767 - val_accuracy: 0.7822 - val_loss: 0.7723 - learning_rate: 0.0010\n",
      "Epoch 16/50\n",
      "\u001b[1m512/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8680 - loss: 0.3668\n",
      "Epoch 16: val_accuracy did not improve from 0.78217\n",
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 19ms/step - accuracy: 0.8680 - loss: 0.3669 - val_accuracy: 0.7792 - val_loss: 0.8334 - learning_rate: 0.0010\n",
      "Epoch 17/50\n",
      "\u001b[1m513/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8680 - loss: 0.3480\n",
      "Epoch 17: val_accuracy did not improve from 0.78217\n",
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - accuracy: 0.8680 - loss: 0.3480 - val_accuracy: 0.7772 - val_loss: 0.8418 - learning_rate: 0.0010\n",
      "Epoch 18/50\n",
      "\u001b[1m513/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8819 - loss: 0.3186\n",
      "Epoch 18: val_accuracy did not improve from 0.78217\n",
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - accuracy: 0.8818 - loss: 0.3187 - val_accuracy: 0.7747 - val_loss: 0.8284 - learning_rate: 0.0010\n",
      "Epoch 19/50\n",
      "\u001b[1m511/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8802 - loss: 0.3229\n",
      "Epoch 19: val_accuracy did not improve from 0.78217\n",
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - accuracy: 0.8802 - loss: 0.3229 - val_accuracy: 0.7711 - val_loss: 0.9250 - learning_rate: 0.0010\n",
      "Epoch 20/50\n",
      "\u001b[1m512/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8871 - loss: 0.3085\n",
      "Epoch 20: val_accuracy did not improve from 0.78217\n",
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - accuracy: 0.8871 - loss: 0.3086 - val_accuracy: 0.7722 - val_loss: 0.9853 - learning_rate: 0.0010\n",
      "Test Accuracy:  0.7721691727638245\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a693d47fe3464eac8d93379adb1e8511",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\smhrd\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:157: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\smhrd\\.cache\\huggingface\\hub\\models--sentence-transformers--multi-qa-distilbert-cos-v1. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "141eb1cfb363419db474eeb458509bb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fe1ff9bf1de4b7289a347dd9c8e8366",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/9.52k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ad60edc1c28429488c6c280fccd5d4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\smhrd\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc6c26d3bfad4233a694522addbd1f86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/523 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8845fc9dead64817af25db78010f8454",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/265M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0c832fafcd44c4f9a1e1112c0b0b8c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/333 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "effb5e050a1a49c2995fd05ef102b81a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f1ec1340a8b463fb82d800a8fb9581b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6203f2943304cf5a893704f19a8b4fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e8b974029a643e694f3555cdcad9225",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m513/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.4503 - loss: 1.4853\n",
      "Epoch 1: val_accuracy did not improve from 0.78217\n",
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - accuracy: 0.4506 - loss: 1.4847 - val_accuracy: 0.5967 - val_loss: 1.1148 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m513/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6261 - loss: 1.0616\n",
      "Epoch 2: val_accuracy did not improve from 0.78217\n",
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 18ms/step - accuracy: 0.6262 - loss: 1.0615 - val_accuracy: 0.6476 - val_loss: 1.0119 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m512/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6729 - loss: 0.9509\n",
      "Epoch 3: val_accuracy did not improve from 0.78217\n",
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 18ms/step - accuracy: 0.6729 - loss: 0.9509 - val_accuracy: 0.6681 - val_loss: 0.9494 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m513/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6931 - loss: 0.8718\n",
      "Epoch 4: val_accuracy did not improve from 0.78217\n",
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 18ms/step - accuracy: 0.6931 - loss: 0.8718 - val_accuracy: 0.6728 - val_loss: 0.9297 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7052 - loss: 0.8317\n",
      "Epoch 5: val_accuracy did not improve from 0.78217\n",
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 18ms/step - accuracy: 0.7052 - loss: 0.8317 - val_accuracy: 0.6767 - val_loss: 0.9221 - learning_rate: 0.0010\n",
      "Test Accuracy:  0.6766712069511414\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e668378e27340bfbac921496b3444fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/229 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\smhrd\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:157: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\smhrd\\.cache\\huggingface\\hub\\models--jhgan--ko-sroberta-multitask. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba633fe56fa04960ba92def233a099e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/123 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "183039314ed94ecc8f8e49c52f140935",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/4.86k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1eb9281f0f3c42acadf6628584cf8b0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\smhrd\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "387ed5e09a354d9e87294bc1df2b6794",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/744 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36928db4a4164ef59a45d592e02f229e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/443M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84df88656fe9446cb602a79eae7e8895",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/585 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d9247c7aa4f4efdbfa7c5103b61bfb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/248k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f29fef0c924b4c7ca568a364b8f42296",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/495k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf88d22dbf7c4899a7420f7df25d5aa4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/156 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c51bd5dbe39b4754b90240c1371ad7e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m512/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.6043 - loss: 1.0813\n",
      "Epoch 1: val_accuracy improved from 0.78217 to 0.79673, saving model to ./model/model_01-0.7967.keras\n",
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - accuracy: 0.6049 - loss: 1.0799 - val_accuracy: 0.7967 - val_loss: 0.6173 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m512/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7974 - loss: 0.6281\n",
      "Epoch 2: val_accuracy improved from 0.79673 to 0.80491, saving model to ./model/model_02-0.8049.keras\n",
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 19ms/step - accuracy: 0.7975 - loss: 0.6280 - val_accuracy: 0.8049 - val_loss: 0.5632 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m511/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8210 - loss: 0.5407\n",
      "Epoch 3: val_accuracy improved from 0.80491 to 0.81071, saving model to ./model/model_03-0.8107.keras\n",
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - accuracy: 0.8211 - loss: 0.5406 - val_accuracy: 0.8107 - val_loss: 0.5468 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m511/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8300 - loss: 0.4916\n",
      "Epoch 4: val_accuracy did not improve from 0.81071\n",
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 18ms/step - accuracy: 0.8300 - loss: 0.4916 - val_accuracy: 0.8043 - val_loss: 0.5669 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8489 - loss: 0.4361\n",
      "Epoch 5: val_accuracy did not improve from 0.81071\n",
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 19ms/step - accuracy: 0.8489 - loss: 0.4361 - val_accuracy: 0.8105 - val_loss: 0.5607 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m512/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8568 - loss: 0.4044\n",
      "Epoch 6: val_accuracy improved from 0.81071 to 0.81958, saving model to ./model/model_06-0.8196.keras\n",
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 19ms/step - accuracy: 0.8568 - loss: 0.4044 - val_accuracy: 0.8196 - val_loss: 0.5825 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m513/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8674 - loss: 0.3845\n",
      "Epoch 7: val_accuracy did not improve from 0.81958\n",
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 19ms/step - accuracy: 0.8674 - loss: 0.3846 - val_accuracy: 0.8124 - val_loss: 0.5899 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m512/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8743 - loss: 0.3516\n",
      "Epoch 8: val_accuracy did not improve from 0.81958\n",
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - accuracy: 0.8743 - loss: 0.3517 - val_accuracy: 0.8161 - val_loss: 0.5979 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m512/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8853 - loss: 0.3169\n",
      "Epoch 9: val_accuracy did not improve from 0.81958\n",
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - accuracy: 0.8853 - loss: 0.3170 - val_accuracy: 0.8156 - val_loss: 0.6356 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m512/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8936 - loss: 0.3011\n",
      "Epoch 10: val_accuracy did not improve from 0.81958\n",
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 19ms/step - accuracy: 0.8935 - loss: 0.3011 - val_accuracy: 0.8075 - val_loss: 0.6713 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m511/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8956 - loss: 0.2809\n",
      "Epoch 11: val_accuracy did not improve from 0.81958\n",
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 19ms/step - accuracy: 0.8956 - loss: 0.2811 - val_accuracy: 0.8121 - val_loss: 0.6982 - learning_rate: 0.0010\n",
      "Test Accuracy:  0.8120736479759216\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd656cfd049348e0a732689eb29bda0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\smhrd\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:157: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\smhrd\\.cache\\huggingface\\hub\\models--sentence-transformers--all-distilroberta-v1. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b4840ae19cf4a59b4e4edff9a37050a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76b04a5c1bde497ea7770e98e789a512",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/10.3k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "995c04ee7fb842499b757cee5f6bfd27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\smhrd\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0931f4e4dd264f729a88eb01a5923004",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/653 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06c65e479e184ddd9d25f5201f849d18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/328M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3ec6738f2da43f7accbe1e9e6b3fb30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/333 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9667485b83e4f82af7c814e5f76a77b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/798k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a499ccc860674812beb5f050e81e42d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1dcc2b8e57434c25b602003585a690d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa4011b3b3c8443fad89401fd42b1344",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af99d483b34f421d83014eaf96866d7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#StandardScaler로 \n",
    "\n",
    "pre_trained_models = ['sentence-transformers/xlm-r-100langs-bert-base-nli-stsb-mean-tokens',\n",
    "'sentence-transformers/multi-qa-distilbert-cos-v1',\n",
    "'jhgan/ko-sroberta-multitask',\n",
    "'all-distilroberta-v1',\n",
    "'jhgan/ko-sbert-multitask',\n",
    "'all-MiniLM-L12-v2', 'jhgan/ko-sroberta-sts']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "for i in pre_trained_models:\n",
    "    txt_embed = text_embedding(model_name = i)\n",
    "    X_embed = txt_embed.transform(X)\n",
    "   \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_embed,y, random_state=0,  test_size = 0.3, stratify = y)\n",
    "\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    X_train_scaled = np.expand_dims(X_train_scaled,axis =1)\n",
    "    X_test_scaled = np.expand_dims(X_test_scaled,axis =1)\n",
    "\n",
    "\n",
    "    model = second_model(X_train_scaled)\n",
    "    history=model.fit(X_train_scaled, y_train, batch_size=40, epochs=50, validation_data=(X_test_scaled, y_test), callbacks=[rlrp,mcp,es])\n",
    "\n",
    "    test_loss, test_acc = model.evaluate(X_test_scaled, y_test, verbose=0)\n",
    "    print(\"Test Accuracy: \",test_acc)\n",
    "\n",
    "    # test 결과값 약 47.5%\n",
    "    \n",
    "    test_loss, test_acc = model.evaluate(X_test_scaled, y_test, verbose=0)\n",
    "    print(\"Pre-trained Model: \", i)\n",
    "    print(\"Test Accuracy: \",test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2024bdb9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
