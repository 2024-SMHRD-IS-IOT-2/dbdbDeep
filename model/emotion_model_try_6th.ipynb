{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02159c55",
   "metadata": {},
   "source": [
    "#### 새로운 시도를 하기 전에 한 번 지금까지 썼던 모델들 다 검토해보기로"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9fd64480",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import librosa\n",
    "# import librosa.display\n",
    "# import IPython.display as ipd\n",
    "# from IPython.display import Audio\n",
    "\n",
    "from random import randint\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import pydub #오디오 파일을 다루는 라이브러리 : 변환 조작 재생 분석 등\n",
    "# import gTTS # 텍스트를 음성으로 변환하는 라이브러리. 나는 당장 쓸 일 없을 듯?\n",
    "\n",
    "# from tqdm import tqdm\n",
    "# import np_utils\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "\n",
    "# import winsound as sd\n",
    "# import glob\n",
    "# import os\n",
    "# import json\n",
    "# import shutil\n",
    "# import sys\n",
    "# import logging\n",
    "# import unicodedata\n",
    "# from shutil import copyfile\n",
    "# import warnings\n",
    "# if not sys.warnoptions:\n",
    "#     warnings.simplefilter(\"ignore\")\n",
    "# warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder,StandardScaler, OneHotEncoder, scale, MinMaxScaler\n",
    "# from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split, KFold, RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import SVC \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import joblib\n",
    "from joblib import dump, load\n",
    "from xgboost import XGBClassifier \n",
    "\n",
    "# import keras\n",
    "from keras.callbacks import ReduceLROnPlateau,ModelCheckpoint,EarlyStopping\n",
    "from keras.models import Sequential\n",
    "from tensorflow.keras.layers import InputLayer, Dense, Conv1D, MaxPooling1D, Flatten, Dropout, LSTM\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "# from keras.preprocessing.sequence import pad_sequences\n",
    "# from keras.utils import to_categorical\n",
    "\n",
    "# import tensorflow\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "\n",
    "# from transformers import PreTrainedTokenizer\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc9390bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_csv = pd.read_csv('e:/Data2/csv/train.csv')\n",
    "valid_csv = pd.read_csv('e:/Data2/csv/valid.csv')\n",
    "X = np.load('./features5.npy')\n",
    "y = train_csv.iloc[:,-7:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41ebe899",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기본적인 사전 설정\n",
    "rlrp = ReduceLROnPlateau(monitor='loss', factor=0.4, verbose=0, patience=5, min_lr=0.0000001) #learning rate 조절 \n",
    "modelpath = './model/model_{epoch:02d}-{val_accuracy:.4f}.keras'\n",
    "mcp = ModelCheckpoint(\n",
    "    modelpath,     #저장할 모델의 경로\n",
    "  monitor = 'val_accuracy', #val_acc를 기준으로 전보다 모델이 나아지는 걸 확인\n",
    "  save_best_only = True,    #나아진 결과만 저장\n",
    "#     save_weights_only=True , #이걸 써 줘야 weights.h5로 저장 가능하다.\n",
    "  verbose = 1               #과정을 출력\n",
    ")\n",
    "\n",
    "#전보다 나아지지 않으면 학습중단\n",
    "\n",
    "es = EarlyStopping(\n",
    "    monitor = 'val_accuracy',\n",
    "    patience = 5      # 전보다 나아지지 않아도 실행할 횟수\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5648cd85",
   "metadata": {},
   "source": [
    "### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9478c5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_model(x_train):\n",
    "    model=Sequential()\n",
    "    model.add(InputLayer(shape=(x_train.shape[1],x_train.shape[2])))\n",
    "    model.add(Conv1D(256, kernel_size=5, strides=1, padding='same', activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_size=5, strides = 2, padding = 'same'))\n",
    "\n",
    "    model.add(Conv1D(256, kernel_size=5, strides=1, padding='same', activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_size=5, strides = 2, padding = 'same'))\n",
    "\n",
    "    model.add(Conv1D(128, kernel_size=5, strides=1, padding='same', activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_size=5, strides = 2, padding = 'same'))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Conv1D(64, kernel_size=5, strides=1, padding='same', activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_size=5, strides = 2, padding = 'same'))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(units=32, activation='relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "    model.add(Dense(units=7, activation='softmax'))\n",
    "    model.compile(optimizer = 'adam' , loss = 'categorical_crossentropy' , metrics = ['accuracy'])\n",
    "\n",
    "    #model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "eafb9582",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m506/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3592 - loss: 1.6858\n",
      "Epoch 1: val_accuracy did not improve from 0.50614\n",
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - accuracy: 0.3598 - loss: 1.6847 - val_accuracy: 0.4484 - val_loss: 1.5184 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m511/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4484 - loss: 1.5211\n",
      "Epoch 2: val_accuracy did not improve from 0.50614\n",
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.4484 - loss: 1.5210 - val_accuracy: 0.4511 - val_loss: 1.4871 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4584 - loss: 1.4783\n",
      "Epoch 3: val_accuracy did not improve from 0.50614\n",
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.4584 - loss: 1.4783 - val_accuracy: 0.4679 - val_loss: 1.4360 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m511/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4747 - loss: 1.4391\n",
      "Epoch 4: val_accuracy did not improve from 0.50614\n",
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.4747 - loss: 1.4391 - val_accuracy: 0.4754 - val_loss: 1.4141 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m506/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4845 - loss: 1.4210\n",
      "Epoch 5: val_accuracy did not improve from 0.50614\n",
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.4845 - loss: 1.4209 - val_accuracy: 0.4750 - val_loss: 1.4300 - learning_rate: 0.0010\n",
      "Test Accuracy:  0.4749886393547058\n"
     ]
    }
   ],
   "source": [
    "#StandardScaler로 \n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "   \n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, random_state=0,  test_size = 0.3, stratify = y)\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "X_train_scaled = np.expand_dims(X_train_scaled,axis =1)\n",
    "X_test_scaled = np.expand_dims(X_test_scaled,axis =1)\n",
    "\n",
    "\n",
    "model = second_model(X_train_scaled)\n",
    "history=model.fit(X_train_scaled, y_train, batch_size=40, epochs=50, validation_data=(X_test_scaled, y_test), callbacks=[rlrp,mcp,es])\n",
    "\n",
    "test_loss, test_acc = model.evaluate(X_test_scaled, y_test, verbose=0)\n",
    "print(\"Test Accuracy: \",test_acc)\n",
    "\n",
    "# test 결과값 약 47.5%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "91685782",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m508/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3723 - loss: 1.7180\n",
      "Epoch 1: val_accuracy did not improve from 0.50614\n",
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - accuracy: 0.3725 - loss: 1.7175 - val_accuracy: 0.3832 - val_loss: 1.6285 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m513/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3932 - loss: 1.6417\n",
      "Epoch 2: val_accuracy did not improve from 0.50614\n",
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.3932 - loss: 1.6417 - val_accuracy: 0.3830 - val_loss: 1.6234 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m513/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3923 - loss: 1.6229\n",
      "Epoch 3: val_accuracy did not improve from 0.50614\n",
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.3923 - loss: 1.6229 - val_accuracy: 0.4051 - val_loss: 1.5886 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m506/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4002 - loss: 1.5998\n",
      "Epoch 4: val_accuracy did not improve from 0.50614\n",
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.4003 - loss: 1.5998 - val_accuracy: 0.4084 - val_loss: 1.5726 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4009 - loss: 1.6033\n",
      "Epoch 5: val_accuracy did not improve from 0.50614\n",
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.4009 - loss: 1.6033 - val_accuracy: 0.4126 - val_loss: 1.5696 - learning_rate: 0.0010\n",
      "Test Accuracy:  0.412573903799057\n"
     ]
    }
   ],
   "source": [
    "#MinMaxScaler로 \n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "   \n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, random_state=0,  test_size = 0.3, stratify = y)\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "X_train_scaled = np.expand_dims(X_train_scaled,axis =1)\n",
    "X_test_scaled = np.expand_dims(X_test_scaled,axis =1)\n",
    "\n",
    "\n",
    "model = second_model(X_train_scaled)\n",
    "history=model.fit(X_train_scaled, y_train, batch_size=40, epochs=50, validation_data=(X_test_scaled, y_test), callbacks=[rlrp,mcp,es])\n",
    "\n",
    "test_loss, test_acc = model.evaluate(X_test_scaled, y_test, verbose=0)\n",
    "print(\"Test Accuracy: \",test_acc)\n",
    "\n",
    "# test 결과값 약 41.2% : CNN은 StandardScaler로"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff52221",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "705fc471",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train KNN Accuracy: 0.4249378745797398\n",
      "Test KNN Accuracy: 0.3358344702137335\n"
     ]
    }
   ],
   "source": [
    "# Define the parameter grid for the random search\n",
    "X_train, X_test, y_train, y_test = train_test_split(X , train_csv['감정'],random_state=0, stratify = train_csv['감정'], test_size = 0.3)\n",
    "\n",
    "\n",
    "\n",
    "# 레이블 인코딩\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "\n",
    "\n",
    "\n",
    "param_grid = {\n",
    "    'n_neighbors': np.arange(1, 15),  # Number of neighbors\n",
    "    'weights': ['uniform', 'distance'],  # Weight function\n",
    "    'p': [1, 2]  # Power parameter for the Minkowski distance metric\n",
    "}\n",
    "\n",
    "# Create the KNN classifier\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "# Perform the random search\n",
    "random_search_knn = RandomizedSearchCV(\n",
    "    knn, param_distributions=param_grid, n_iter=10, cv=5, random_state=42\n",
    ")\n",
    "random_search_knn.fit(X_train, y_train_encoded)\n",
    "\n",
    "# Evaluate the KNN model with the best parameters on the test set\n",
    "best_knn = random_search_knn.best_estimator_\n",
    "y_pred_knn = best_knn.predict(X_test)\n",
    "test_accuracy_knn = accuracy_score(y_test_encoded, y_pred_knn)\n",
    "\n",
    "# Evaluate the KNN model on the training set\n",
    "y_train_pred_knn = best_knn.predict(X_train)\n",
    "train_accuracy_knn = accuracy_score(y_train_encoded, y_train_pred_knn)\n",
    "\n",
    "print(\"Train KNN Accuracy:\", train_accuracy_knn)\n",
    "print(\"Test KNN Accuracy:\", test_accuracy_knn)\n",
    "\n",
    "\n",
    "#test 결과값 약 33% 나옴"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c98f5c1",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "52a074a1",
   "metadata": {},
   "outputs": [],
   "source": [
    " def lstm_model(X_train):\n",
    "    model = Sequential()\n",
    "    model.add(InputLayer(shape=(X_train.shape[1],X_train.shape[2])))\n",
    "    model.add(LSTM(64, return_sequences=True)) \n",
    "    model.add(LSTM(32)) \n",
    "    model.add(Dense(128,activation='relu'))\n",
    "    model.add(Dense(7, activation='softmax'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c1c51aa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m455/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3301 - loss: 0.4530\n",
      "Epoch 1: val_accuracy did not improve from 0.81958\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.3327 - loss: 0.4493 - val_accuracy: 0.4216 - val_loss: 0.3428 - learning_rate: 0.0010\n",
      "Epoch 2/30\n",
      "\u001b[1m440/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4317 - loss: 0.3357\n",
      "Epoch 2: val_accuracy did not improve from 0.81958\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.4325 - loss: 0.3354 - val_accuracy: 0.4530 - val_loss: 0.3296 - learning_rate: 0.0010\n",
      "Epoch 3/30\n",
      "\u001b[1m446/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4613 - loss: 0.3242\n",
      "Epoch 3: val_accuracy did not improve from 0.81958\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.4614 - loss: 0.3241 - val_accuracy: 0.4665 - val_loss: 0.3237 - learning_rate: 0.0010\n",
      "Epoch 4/30\n",
      "\u001b[1m461/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4747 - loss: 0.3162\n",
      "Epoch 4: val_accuracy did not improve from 0.81958\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4748 - loss: 0.3162 - val_accuracy: 0.4694 - val_loss: 0.3219 - learning_rate: 0.0010\n",
      "Epoch 5/30\n",
      "\u001b[1m442/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4873 - loss: 0.3117\n",
      "Epoch 5: val_accuracy did not improve from 0.81958\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.4877 - loss: 0.3116 - val_accuracy: 0.4726 - val_loss: 0.3185 - learning_rate: 0.0010\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0, stratify = y, test_size = 0.3)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled  = scaler.transform(X_test)\n",
    "\n",
    "X_train_scaled = np.expand_dims(X_train_scaled,axis =1)\n",
    "X_test_scaled = np.expand_dims(X_test_scaled,axis =1)\n",
    "\n",
    "model = lstm_model(X_train_scaled)\n",
    "\n",
    "h1 = model.fit(X_train_scaled,y_train,\n",
    "               validation_split = 0.3,\n",
    "               epochs=30,\n",
    "               batch_size=30,callbacks=[rlrp,es,mcp])\n",
    "\n",
    "#test 결과값 약 46.8% 정도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4be48111",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m447/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4046 - loss: 0.3499\n",
      "Epoch 1: val_accuracy did not improve from 0.50807\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4044 - loss: 0.3498 - val_accuracy: 0.4174 - val_loss: 0.3453 - learning_rate: 0.0010\n",
      "Epoch 2/30\n",
      "\u001b[1m454/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4147 - loss: 0.3441\n",
      "Epoch 2: val_accuracy did not improve from 0.50807\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.4148 - loss: 0.3440 - val_accuracy: 0.4096 - val_loss: 0.3454 - learning_rate: 0.0010\n",
      "Epoch 3/30\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4193 - loss: 0.3422\n",
      "Epoch 3: val_accuracy did not improve from 0.50807\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.4194 - loss: 0.3421 - val_accuracy: 0.4328 - val_loss: 0.3396 - learning_rate: 0.0010\n",
      "Epoch 4/30\n",
      "\u001b[1m462/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4339 - loss: 0.3357\n",
      "Epoch 4: val_accuracy did not improve from 0.50807\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.4341 - loss: 0.3357 - val_accuracy: 0.4410 - val_loss: 0.3343 - learning_rate: 0.0010\n",
      "Epoch 5/30\n",
      "\u001b[1m448/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4457 - loss: 0.3342\n",
      "Epoch 5: val_accuracy did not improve from 0.50807\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.4456 - loss: 0.3341 - val_accuracy: 0.4296 - val_loss: 0.3359 - learning_rate: 0.0010\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0, stratify = y, test_size = 0.3)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled  = scaler.transform(X_test)\n",
    "\n",
    "X_train_scaled = np.expand_dims(X_train_scaled,axis =1)\n",
    "X_test_scaled = np.expand_dims(X_test_scaled,axis =1)\n",
    "\n",
    "model = lstm_model(X_train_scaled)\n",
    "\n",
    "h1 = model.fit(X_train_scaled,y_train,\n",
    "               validation_split = 0.3,\n",
    "               epochs=30,\n",
    "               batch_size=30,callbacks=[rlrp,es,mcp])\n",
    "\n",
    "#test 결과값 약 42.7% 정도. LSTM은 StandardScaler로"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0018387",
   "metadata": {},
   "source": [
    "### SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "672f4999",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도 : 0.5160300136425648\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train,y_test =train_test_split(X,train_csv['감정'],random_state=5,stratify=train_csv['감정'],test_size=0.3)\n",
    "#MinMAx Scaler을 이용한 특징 벡터 전처리\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# 레이블 인코딩\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "\n",
    "\n",
    "#분류기 커널 설정\n",
    "clf = SVC(C=100, kernel='rbf', probability=True)\n",
    "#분류기 학습\n",
    "clf.fit(X_train_scaled, y_train_encoded )\n",
    "#각 row의 클래스별 확률을 구하기\n",
    "probabilities = clf.predict_proba(X_test_scaled)\n",
    "print(\"첫 번째 샘플의 클래스별 확률:\", probabilities[0])\n",
    "#예측 결과\n",
    "y_pred = clf.predict(X_test_scaled)\n",
    "accuracy = accuracy_score(y_pred, y_test_encoded)\n",
    "    \n",
    "\n",
    "    \n",
    "print(\"정확도 :\", accuracy)\n",
    "\n",
    "#test 결과값 약 51.6% 정도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fc069824",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "첫 번째 샘플의 클래스별 확률: [0.20003447 0.10426802 0.08509696 0.04807575 0.17558152 0.35403075\n",
      " 0.03291253]\n",
      "정확도 : 0.47510231923601637\n"
     ]
    }
   ],
   "source": [
    "#Scaler를 StandardScaler로\n",
    "\n",
    "X_train, X_test, y_train,y_test =train_test_split(X,train_csv['감정'],random_state=5,stratify=train_csv['감정'],test_size=0.3)\n",
    "#StandardScaler을 이용한 특징 벡터 전처리\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# 레이블 인코딩\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "\n",
    "\n",
    "#분류기 커널 설정\n",
    "clf = SVC(C=100, kernel='rbf', probability=True)\n",
    "#분류기 학습\n",
    "clf.fit(X_train_scaled, y_train_encoded )\n",
    "#각 row의 클래스별 확률을 구하기\n",
    "probabilities = clf.predict_proba(X_test_scaled)\n",
    "print(\"첫 번째 샘플의 클래스별 확률:\", probabilities[0])\n",
    "#예측 결과\n",
    "y_pred = clf.predict(X_test_scaled)\n",
    "accuracy = accuracy_score(y_pred, y_test_encoded)\n",
    "    \n",
    "\n",
    "    \n",
    "print(\"정확도 :\", accuracy)\n",
    "\n",
    "#test 결과값 약 47.5% 정도. SVC에서는 MinMaxScaler로"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f655803",
   "metadata": {},
   "source": [
    "### ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "877a0a14",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\smhrd\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m623/642\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3924 - loss: 1.6399\n",
      "Epoch 1: val_accuracy did not improve from 0.50807\n",
      "\u001b[1m642/642\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.3932 - loss: 1.6378 - val_accuracy: 0.4578 - val_loss: 1.4724 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "\u001b[1m616/642\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4463 - loss: 1.4941\n",
      "Epoch 2: val_accuracy did not improve from 0.50807\n",
      "\u001b[1m642/642\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4465 - loss: 1.4937 - val_accuracy: 0.4773 - val_loss: 1.4357 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "\u001b[1m630/642\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4760 - loss: 1.4297\n",
      "Epoch 3: val_accuracy did not improve from 0.50807\n",
      "\u001b[1m642/642\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4758 - loss: 1.4300 - val_accuracy: 0.4717 - val_loss: 1.4341 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "\u001b[1m641/642\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4723 - loss: 1.4235\n",
      "Epoch 4: val_accuracy did not improve from 0.50807\n",
      "\u001b[1m642/642\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4723 - loss: 1.4234 - val_accuracy: 0.4765 - val_loss: 1.4274 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "\u001b[1m611/642\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4825 - loss: 1.3928\n",
      "Epoch 5: val_accuracy did not improve from 0.50807\n",
      "\u001b[1m642/642\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4823 - loss: 1.3934 - val_accuracy: 0.4724 - val_loss: 1.4182 - learning_rate: 0.0010\n",
      "\u001b[1m275/275\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 853us/step\n",
      "Training accuracy: 0.4784388244152069\n",
      "Validation accuracy: 0.4723738133907318\n",
      "Test accuracy: 0.3993860845839018\n"
     ]
    }
   ],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,y,random_state=5,stratify=y,test_size=0.3)\n",
    "\n",
    "scaler =StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "# Define the model architecture\n",
    "model = Sequential()\n",
    "model.add(Dense(units=256, activation='relu', input_dim=X_train.shape[1]))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(units=256, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(units=256, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(units=256, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(units=7, activation='softmax'))  # Adjusted to use np.unique for flexibility\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Fit the model\n",
    "history = model.fit(X_train_scaled, y_train, epochs=100, batch_size=32, verbose=1, validation_data=(X_test_scaled, y_test),callbacks=[rlrp,mcp,es])\n",
    "\n",
    "# Retrieve training and validation accuracy\n",
    "train_accuracy = history.history['accuracy'][-1]  # Last epoch accuracy\n",
    "val_accuracy = history.history['val_accuracy'][-1]  # Last epoch validation accuracy\n",
    "\n",
    "# Predict on test set\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "# 임계값 설정\n",
    "threshold = 0.3\n",
    "\n",
    "# 확률이 임계값보다 크면 1로, 작으면 0으로 분류\n",
    "y_pred_labels = (y_pred > threshold).astype(int)\n",
    "# y_pred_labels = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Calculate test accuracy\n",
    "test_accuracy = accuracy_score(y_test, y_pred_labels)\n",
    "\n",
    "# Print accuracies\n",
    "print('Training accuracy:', train_accuracy)\n",
    "print('Validation accuracy:', val_accuracy)\n",
    "print('Test accuracy:', test_accuracy)\n",
    "\n",
    "#test 결과값 약 39.9%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dbb85122",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\smhrd\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m640/642\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3816 - loss: 1.6601\n",
      "Epoch 1: val_accuracy did not improve from 0.50807\n",
      "\u001b[1m642/642\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.3816 - loss: 1.6600 - val_accuracy: 0.4048 - val_loss: 1.6065 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "\u001b[1m629/642\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4023 - loss: 1.5928\n",
      "Epoch 2: val_accuracy did not improve from 0.50807\n",
      "\u001b[1m642/642\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4023 - loss: 1.5928 - val_accuracy: 0.3906 - val_loss: 1.6358 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "\u001b[1m625/642\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4080 - loss: 1.5766\n",
      "Epoch 3: val_accuracy did not improve from 0.50807\n",
      "\u001b[1m642/642\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4081 - loss: 1.5765 - val_accuracy: 0.4173 - val_loss: 1.5588 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "\u001b[1m626/642\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4138 - loss: 1.5649\n",
      "Epoch 4: val_accuracy did not improve from 0.50807\n",
      "\u001b[1m642/642\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4139 - loss: 1.5647 - val_accuracy: 0.4361 - val_loss: 1.5239 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "\u001b[1m628/642\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4236 - loss: 1.5524\n",
      "Epoch 5: val_accuracy did not improve from 0.50807\n",
      "\u001b[1m642/642\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4236 - loss: 1.5522 - val_accuracy: 0.4212 - val_loss: 1.5416 - learning_rate: 0.0010\n",
      "\u001b[1m275/275\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 892us/step\n",
      "Training accuracy: 0.4235248267650604\n",
      "Validation accuracy: 0.42121419310569763\n",
      "Test accuracy: 0.3848340154615734\n"
     ]
    }
   ],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,y,random_state=5,stratify=y,test_size=0.3)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "scaler.fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "# Define the model architecture\n",
    "model = Sequential()\n",
    "model.add(Dense(units=256, activation='relu', input_dim=X_train.shape[1]))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(units=256, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(units=256, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(units=256, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(units=7, activation='softmax'))  # Adjusted to use np.unique for flexibility\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Fit the model\n",
    "history = model.fit(X_train_scaled, y_train, epochs=100, batch_size=32, verbose=1, validation_data=(X_test_scaled, y_test),callbacks=[rlrp,mcp,es])\n",
    "\n",
    "# Retrieve training and validation accuracy\n",
    "train_accuracy = history.history['accuracy'][-1]  # Last epoch accuracy\n",
    "val_accuracy = history.history['val_accuracy'][-1]  # Last epoch validation accuracy\n",
    "\n",
    "# Predict on test set\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "# 임계값 설정\n",
    "threshold = 0.3\n",
    "\n",
    "# 확률이 임계값보다 크면 1로, 작으면 0으로 분류\n",
    "y_pred_labels = (y_pred > threshold).astype(int)\n",
    "# y_pred_labels = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Calculate test accuracy\n",
    "test_accuracy = accuracy_score(y_test, y_pred_labels)\n",
    "\n",
    "# Print accuracies\n",
    "print('Training accuracy:', train_accuracy)\n",
    "print('Validation accuracy:', val_accuracy)\n",
    "print('Test accuracy:', test_accuracy)\n",
    "\n",
    "#test 결과값 약 38.4% 큰 차이는 아니지만 StandardScaler 성능이 더 좋다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f30fb77",
   "metadata": {},
   "source": [
    "### Xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fc008f90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.29\n"
     ]
    }
   ],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,y,random_state=5,stratify=y,test_size=0.3)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "xgb = XGBClassifier(n_estimators=1000, learning_rate=0.05) #1000개의 가지? epoch? , 0.05 학습률\n",
    "xgb.fit(X_train_scaled, y_train) #학습\n",
    "\n",
    "y_preds = xgb.predict(X_test_scaled) #검증\n",
    "\n",
    "print('Accuracy: %.2f' % accuracy_score(y_test,y_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa89095d",
   "metadata": {},
   "source": [
    "### 확인 결과\n",
    "- CNN, LSTM, SVC의 성능이 괜찮은 것으로 보임\n",
    "- 이제 이걸 텍스트 모델과 결합하는 형태로 실행해 보자.\n",
    "- CNN은 StandardScaler,LSTM은 StandardScaler,SVC에서는 MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "46b4c42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 임베딩 함수 설정\n",
    "class text_embedding():\n",
    "    def __init__(self, model_name):\n",
    "        self.model_name = model_name\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "  \n",
    "    def transform(self, X):\n",
    "        embedding_model = SentenceTransformer(self.model_name)\n",
    "        embedding_vec = embedding_model.encode(train_csv['발화문'])\n",
    "        X_val = np.concatenate((X, embedding_vec), axis = 1)\n",
    "        return X_val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60cf11ab",
   "metadata": {},
   "source": [
    "### CNN 모델(텍스트 임베딩)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bbc19a3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\smhrd\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m512/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5671 - loss: 1.2032\n",
      "Epoch 1: val_accuracy improved from 0.50807 to 0.72465, saving model to ./model/model_01-0.7246.keras\n",
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - accuracy: 0.5676 - loss: 1.2021 - val_accuracy: 0.7246 - val_loss: 0.7837 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m512/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7173 - loss: 0.8205\n",
      "Epoch 2: val_accuracy improved from 0.72465 to 0.73499, saving model to ./model/model_02-0.7350.keras\n",
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 19ms/step - accuracy: 0.7174 - loss: 0.8203 - val_accuracy: 0.7350 - val_loss: 0.7375 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m513/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7594 - loss: 0.6963\n",
      "Epoch 3: val_accuracy improved from 0.73499 to 0.74761, saving model to ./model/model_03-0.7476.keras\n",
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 19ms/step - accuracy: 0.7594 - loss: 0.6962 - val_accuracy: 0.7476 - val_loss: 0.7252 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7756 - loss: 0.6646\n",
      "Epoch 4: val_accuracy improved from 0.74761 to 0.76626, saving model to ./model/model_04-0.7663.keras\n",
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - accuracy: 0.7756 - loss: 0.6645 - val_accuracy: 0.7663 - val_loss: 0.6704 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7899 - loss: 0.5941\n",
      "Epoch 5: val_accuracy improved from 0.76626 to 0.76648, saving model to ./model/model_05-0.7665.keras\n",
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - accuracy: 0.7898 - loss: 0.5942 - val_accuracy: 0.7665 - val_loss: 0.7073 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7995 - loss: 0.5721\n",
      "Epoch 6: val_accuracy improved from 0.76648 to 0.76864, saving model to ./model/model_06-0.7686.keras\n",
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - accuracy: 0.7995 - loss: 0.5721 - val_accuracy: 0.7686 - val_loss: 0.6905 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8098 - loss: 0.5308\n",
      "Epoch 7: val_accuracy did not improve from 0.76864\n",
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - accuracy: 0.8098 - loss: 0.5308 - val_accuracy: 0.7656 - val_loss: 0.7138 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m513/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8166 - loss: 0.5233\n",
      "Epoch 8: val_accuracy did not improve from 0.76864\n",
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - accuracy: 0.8166 - loss: 0.5233 - val_accuracy: 0.7685 - val_loss: 0.6966 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8243 - loss: 0.4769\n",
      "Epoch 9: val_accuracy improved from 0.76864 to 0.77240, saving model to ./model/model_09-0.7724.keras\n",
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 19ms/step - accuracy: 0.8243 - loss: 0.4769 - val_accuracy: 0.7724 - val_loss: 0.6920 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8304 - loss: 0.4609\n",
      "Epoch 10: val_accuracy improved from 0.77240 to 0.77501, saving model to ./model/model_10-0.7750.keras\n",
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - accuracy: 0.8304 - loss: 0.4609 - val_accuracy: 0.7750 - val_loss: 0.6837 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m512/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8371 - loss: 0.4448\n",
      "Epoch 11: val_accuracy did not improve from 0.77501\n",
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - accuracy: 0.8371 - loss: 0.4449 - val_accuracy: 0.7659 - val_loss: 0.6952 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8460 - loss: 0.4285\n",
      "Epoch 12: val_accuracy did not improve from 0.77501\n",
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - accuracy: 0.8460 - loss: 0.4285 - val_accuracy: 0.7627 - val_loss: 0.7453 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m513/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8503 - loss: 0.4139\n",
      "Epoch 13: val_accuracy improved from 0.77501 to 0.77513, saving model to ./model/model_13-0.7751.keras\n",
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - accuracy: 0.8503 - loss: 0.4139 - val_accuracy: 0.7751 - val_loss: 0.7482 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8522 - loss: 0.3910\n",
      "Epoch 14: val_accuracy improved from 0.77513 to 0.77967, saving model to ./model/model_14-0.7797.keras\n",
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - accuracy: 0.8522 - loss: 0.3911 - val_accuracy: 0.7797 - val_loss: 0.7405 - learning_rate: 0.0010\n",
      "Epoch 15/50\n",
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8612 - loss: 0.3767\n",
      "Epoch 15: val_accuracy improved from 0.77967 to 0.78217, saving model to ./model/model_15-0.7822.keras\n",
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - accuracy: 0.8612 - loss: 0.3767 - val_accuracy: 0.7822 - val_loss: 0.7723 - learning_rate: 0.0010\n",
      "Epoch 16/50\n",
      "\u001b[1m512/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8680 - loss: 0.3668\n",
      "Epoch 16: val_accuracy did not improve from 0.78217\n",
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 19ms/step - accuracy: 0.8680 - loss: 0.3669 - val_accuracy: 0.7792 - val_loss: 0.8334 - learning_rate: 0.0010\n",
      "Epoch 17/50\n",
      "\u001b[1m513/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8680 - loss: 0.3480\n",
      "Epoch 17: val_accuracy did not improve from 0.78217\n",
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - accuracy: 0.8680 - loss: 0.3480 - val_accuracy: 0.7772 - val_loss: 0.8418 - learning_rate: 0.0010\n",
      "Epoch 18/50\n",
      "\u001b[1m513/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8819 - loss: 0.3186\n",
      "Epoch 18: val_accuracy did not improve from 0.78217\n",
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - accuracy: 0.8818 - loss: 0.3187 - val_accuracy: 0.7747 - val_loss: 0.8284 - learning_rate: 0.0010\n",
      "Epoch 19/50\n",
      "\u001b[1m511/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8802 - loss: 0.3229\n",
      "Epoch 19: val_accuracy did not improve from 0.78217\n",
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - accuracy: 0.8802 - loss: 0.3229 - val_accuracy: 0.7711 - val_loss: 0.9250 - learning_rate: 0.0010\n",
      "Epoch 20/50\n",
      "\u001b[1m512/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8871 - loss: 0.3085\n",
      "Epoch 20: val_accuracy did not improve from 0.78217\n",
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - accuracy: 0.8871 - loss: 0.3086 - val_accuracy: 0.7722 - val_loss: 0.9853 - learning_rate: 0.0010\n",
      "Test Accuracy:  0.7721691727638245\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a693d47fe3464eac8d93379adb1e8511",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\smhrd\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:157: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\smhrd\\.cache\\huggingface\\hub\\models--sentence-transformers--multi-qa-distilbert-cos-v1. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "141eb1cfb363419db474eeb458509bb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fe1ff9bf1de4b7289a347dd9c8e8366",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/9.52k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ad60edc1c28429488c6c280fccd5d4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\smhrd\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc6c26d3bfad4233a694522addbd1f86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/523 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8845fc9dead64817af25db78010f8454",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/265M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0c832fafcd44c4f9a1e1112c0b0b8c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/333 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "effb5e050a1a49c2995fd05ef102b81a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f1ec1340a8b463fb82d800a8fb9581b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6203f2943304cf5a893704f19a8b4fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e8b974029a643e694f3555cdcad9225",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m513/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.4503 - loss: 1.4853\n",
      "Epoch 1: val_accuracy did not improve from 0.78217\n",
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - accuracy: 0.4506 - loss: 1.4847 - val_accuracy: 0.5967 - val_loss: 1.1148 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m513/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6261 - loss: 1.0616\n",
      "Epoch 2: val_accuracy did not improve from 0.78217\n",
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 18ms/step - accuracy: 0.6262 - loss: 1.0615 - val_accuracy: 0.6476 - val_loss: 1.0119 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m512/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6729 - loss: 0.9509\n",
      "Epoch 3: val_accuracy did not improve from 0.78217\n",
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 18ms/step - accuracy: 0.6729 - loss: 0.9509 - val_accuracy: 0.6681 - val_loss: 0.9494 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m513/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6931 - loss: 0.8718\n",
      "Epoch 4: val_accuracy did not improve from 0.78217\n",
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 18ms/step - accuracy: 0.6931 - loss: 0.8718 - val_accuracy: 0.6728 - val_loss: 0.9297 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7052 - loss: 0.8317\n",
      "Epoch 5: val_accuracy did not improve from 0.78217\n",
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 18ms/step - accuracy: 0.7052 - loss: 0.8317 - val_accuracy: 0.6767 - val_loss: 0.9221 - learning_rate: 0.0010\n",
      "Test Accuracy:  0.6766712069511414\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e668378e27340bfbac921496b3444fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/229 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\smhrd\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:157: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\smhrd\\.cache\\huggingface\\hub\\models--jhgan--ko-sroberta-multitask. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba633fe56fa04960ba92def233a099e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/123 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "183039314ed94ecc8f8e49c52f140935",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/4.86k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1eb9281f0f3c42acadf6628584cf8b0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\smhrd\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "387ed5e09a354d9e87294bc1df2b6794",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/744 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36928db4a4164ef59a45d592e02f229e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/443M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84df88656fe9446cb602a79eae7e8895",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/585 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d9247c7aa4f4efdbfa7c5103b61bfb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/248k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f29fef0c924b4c7ca568a364b8f42296",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/495k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf88d22dbf7c4899a7420f7df25d5aa4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/156 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c51bd5dbe39b4754b90240c1371ad7e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m512/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.6043 - loss: 1.0813\n",
      "Epoch 1: val_accuracy improved from 0.78217 to 0.79673, saving model to ./model/model_01-0.7967.keras\n",
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - accuracy: 0.6049 - loss: 1.0799 - val_accuracy: 0.7967 - val_loss: 0.6173 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m512/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7974 - loss: 0.6281\n",
      "Epoch 2: val_accuracy improved from 0.79673 to 0.80491, saving model to ./model/model_02-0.8049.keras\n",
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 19ms/step - accuracy: 0.7975 - loss: 0.6280 - val_accuracy: 0.8049 - val_loss: 0.5632 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m511/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8210 - loss: 0.5407\n",
      "Epoch 3: val_accuracy improved from 0.80491 to 0.81071, saving model to ./model/model_03-0.8107.keras\n",
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - accuracy: 0.8211 - loss: 0.5406 - val_accuracy: 0.8107 - val_loss: 0.5468 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m511/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8300 - loss: 0.4916\n",
      "Epoch 4: val_accuracy did not improve from 0.81071\n",
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 18ms/step - accuracy: 0.8300 - loss: 0.4916 - val_accuracy: 0.8043 - val_loss: 0.5669 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8489 - loss: 0.4361\n",
      "Epoch 5: val_accuracy did not improve from 0.81071\n",
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 19ms/step - accuracy: 0.8489 - loss: 0.4361 - val_accuracy: 0.8105 - val_loss: 0.5607 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m512/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8568 - loss: 0.4044\n",
      "Epoch 6: val_accuracy improved from 0.81071 to 0.81958, saving model to ./model/model_06-0.8196.keras\n",
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 19ms/step - accuracy: 0.8568 - loss: 0.4044 - val_accuracy: 0.8196 - val_loss: 0.5825 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m513/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8674 - loss: 0.3845\n",
      "Epoch 7: val_accuracy did not improve from 0.81958\n",
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 19ms/step - accuracy: 0.8674 - loss: 0.3846 - val_accuracy: 0.8124 - val_loss: 0.5899 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m512/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8743 - loss: 0.3516\n",
      "Epoch 8: val_accuracy did not improve from 0.81958\n",
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - accuracy: 0.8743 - loss: 0.3517 - val_accuracy: 0.8161 - val_loss: 0.5979 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m512/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8853 - loss: 0.3169\n",
      "Epoch 9: val_accuracy did not improve from 0.81958\n",
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - accuracy: 0.8853 - loss: 0.3170 - val_accuracy: 0.8156 - val_loss: 0.6356 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m512/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8936 - loss: 0.3011\n",
      "Epoch 10: val_accuracy did not improve from 0.81958\n",
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 19ms/step - accuracy: 0.8935 - loss: 0.3011 - val_accuracy: 0.8075 - val_loss: 0.6713 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m511/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8956 - loss: 0.2809\n",
      "Epoch 11: val_accuracy did not improve from 0.81958\n",
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 19ms/step - accuracy: 0.8956 - loss: 0.2811 - val_accuracy: 0.8121 - val_loss: 0.6982 - learning_rate: 0.0010\n",
      "Test Accuracy:  0.8120736479759216\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd656cfd049348e0a732689eb29bda0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\smhrd\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:157: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\smhrd\\.cache\\huggingface\\hub\\models--sentence-transformers--all-distilroberta-v1. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b4840ae19cf4a59b4e4edff9a37050a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76b04a5c1bde497ea7770e98e789a512",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/10.3k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "995c04ee7fb842499b757cee5f6bfd27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\smhrd\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0931f4e4dd264f729a88eb01a5923004",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/653 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06c65e479e184ddd9d25f5201f849d18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/328M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3ec6738f2da43f7accbe1e9e6b3fb30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/333 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9667485b83e4f82af7c814e5f76a77b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/798k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a499ccc860674812beb5f050e81e42d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1dcc2b8e57434c25b602003585a690d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa4011b3b3c8443fad89401fd42b1344",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af99d483b34f421d83014eaf96866d7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m513/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.4775 - loss: 1.4336\n",
      "Epoch 1: val_accuracy did not improve from 0.81958\n",
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - accuracy: 0.4778 - loss: 1.4328 - val_accuracy: 0.6340 - val_loss: 0.9972 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m511/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.6566 - loss: 0.9666\n",
      "Epoch 2: val_accuracy did not improve from 0.81958\n",
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 19ms/step - accuracy: 0.6567 - loss: 0.9663 - val_accuracy: 0.6839 - val_loss: 0.8976 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m512/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7080 - loss: 0.8395\n",
      "Epoch 3: val_accuracy did not improve from 0.81958\n",
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 19ms/step - accuracy: 0.7080 - loss: 0.8395 - val_accuracy: 0.7078 - val_loss: 0.8565 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m512/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7348 - loss: 0.7581\n",
      "Epoch 4: val_accuracy did not improve from 0.81958\n",
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 19ms/step - accuracy: 0.7349 - loss: 0.7581 - val_accuracy: 0.7101 - val_loss: 0.8347 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m512/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7625 - loss: 0.6887\n",
      "Epoch 5: val_accuracy did not improve from 0.81958\n",
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 19ms/step - accuracy: 0.7625 - loss: 0.6887 - val_accuracy: 0.7179 - val_loss: 0.8138 - learning_rate: 0.0010\n",
      "Test Accuracy:  0.7179399728775024\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fc2424a933943118f7dd198b030c2d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/229 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\smhrd\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:157: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\smhrd\\.cache\\huggingface\\hub\\models--jhgan--ko-sbert-multitask. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "794d8784154d411d9b768f8476de995e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/123 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42655a637d7e411e89eb89ff6b6c0f09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/4.78k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7743a9e8e7f04a60821d9e864434da9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\smhrd\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de69be5ea82f4105b876477bef0aaa56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/620 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38e78f9b58f64765beb197fec9131ac2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/443M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dff2314e06f345128f0351ebf9042576",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/538 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8dd6928b9f1451da3032988cae84d41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/248k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0570bd1084c48eaa268d2d917940690",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/495k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e4dc1c4db6f4939b1771d6c0958cf2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcce3586a82440ef99e5d793eb659ce9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m512/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.6299 - loss: 1.0403\n",
      "Epoch 1: val_accuracy did not improve from 0.81958\n",
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - accuracy: 0.6304 - loss: 1.0390 - val_accuracy: 0.7855 - val_loss: 0.6288 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m513/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8001 - loss: 0.6150\n",
      "Epoch 2: val_accuracy did not improve from 0.81958\n",
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - accuracy: 0.8001 - loss: 0.6149 - val_accuracy: 0.7857 - val_loss: 0.5898 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m512/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8181 - loss: 0.5353\n",
      "Epoch 3: val_accuracy did not improve from 0.81958\n",
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 21ms/step - accuracy: 0.8180 - loss: 0.5353 - val_accuracy: 0.8084 - val_loss: 0.5527 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m512/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8398 - loss: 0.4690\n",
      "Epoch 4: val_accuracy did not improve from 0.81958\n",
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - accuracy: 0.8397 - loss: 0.4691 - val_accuracy: 0.8150 - val_loss: 0.5307 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m512/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8440 - loss: 0.4469\n",
      "Epoch 5: val_accuracy did not improve from 0.81958\n",
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 19ms/step - accuracy: 0.8440 - loss: 0.4470 - val_accuracy: 0.8181 - val_loss: 0.5518 - learning_rate: 0.0010\n",
      "Test Accuracy:  0.8180991411209106\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04d4b3241a294389b774c554c7b94684",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\smhrd\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:157: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\smhrd\\.cache\\huggingface\\hub\\models--sentence-transformers--all-MiniLM-L12-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfa2745efe1b4262bf6417c039a75d63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52eaaf3ec9f9415e8c7f2aa80a7c3937",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/10.7k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28887549a89b46418068253c384f8684",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\smhrd\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d93599e4d4734f4bab0720d6bd5adc63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/615 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80c1aaf5e7d143deba8c00aa9dd05efe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/133M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e3fc84f70424cafae6bd7995286bbdd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/352 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8a54006478e493a8daa4a6a9061af14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98b9aff638dc4d36b551d84fe2d54473",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52bcef04cf324baf8ca87f1a936d4527",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08ac40c239704ece8017764ccbdd7ca4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m511/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.4325 - loss: 1.5548\n",
      "Epoch 1: val_accuracy did not improve from 0.81958\n",
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - accuracy: 0.4330 - loss: 1.5534 - val_accuracy: 0.6124 - val_loss: 1.0927 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6231 - loss: 1.0933\n",
      "Epoch 2: val_accuracy did not improve from 0.81958\n",
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - accuracy: 0.6231 - loss: 1.0932 - val_accuracy: 0.6397 - val_loss: 1.0066 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m510/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6665 - loss: 0.9547\n",
      "Epoch 3: val_accuracy did not improve from 0.81958\n",
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - accuracy: 0.6665 - loss: 0.9548 - val_accuracy: 0.6536 - val_loss: 0.9923 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6966 - loss: 0.8750\n",
      "Epoch 4: val_accuracy did not improve from 0.81958\n",
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - accuracy: 0.6966 - loss: 0.8750 - val_accuracy: 0.6614 - val_loss: 0.9630 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m511/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7216 - loss: 0.8048\n",
      "Epoch 5: val_accuracy did not improve from 0.81958\n",
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - accuracy: 0.7215 - loss: 0.8049 - val_accuracy: 0.6776 - val_loss: 0.9310 - learning_rate: 0.0010\n",
      "Test Accuracy:  0.677580714225769\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8e9986c252b4b8f9dd360d6a78bca5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/229 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\smhrd\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:157: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\smhrd\\.cache\\huggingface\\hub\\models--jhgan--ko-sroberta-sts. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1eb33131733e4147b6937b09368deef6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/123 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fd3b60408ca4c1c949f38898eb179a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/4.00k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b353837aae284868b3ff2b480fe37049",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\smhrd\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "986a21e8b13d49dd91aaa175985a3084",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/744 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3032dc930a649a7943510181ddb41e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/443M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71dfa6efed334a21aa327febfdbcc03a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/585 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b0c854e0caa4dffba2fad176596d12d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/248k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e58d3ab6947f4020890fd8c3d9ec0dad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/495k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7a1563880d546ae85762624a8145807",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/156 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc64a3a18eb34a0780d31f54c679969d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m513/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.6263 - loss: 1.0748\n",
      "Epoch 1: val_accuracy did not improve from 0.81958\n",
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 21ms/step - accuracy: 0.6266 - loss: 1.0738 - val_accuracy: 0.7926 - val_loss: 0.6059 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8035 - loss: 0.5994\n",
      "Epoch 2: val_accuracy did not improve from 0.81958\n",
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 19ms/step - accuracy: 0.8034 - loss: 0.5994 - val_accuracy: 0.7983 - val_loss: 0.5625 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8239 - loss: 0.5193\n",
      "Epoch 3: val_accuracy did not improve from 0.81958\n",
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - accuracy: 0.8239 - loss: 0.5193 - val_accuracy: 0.8032 - val_loss: 0.5662 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m513/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8409 - loss: 0.4671\n",
      "Epoch 4: val_accuracy did not improve from 0.81958\n",
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - accuracy: 0.8409 - loss: 0.4671 - val_accuracy: 0.8063 - val_loss: 0.5966 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m513/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8548 - loss: 0.4228\n",
      "Epoch 5: val_accuracy did not improve from 0.81958\n",
      "\u001b[1m514/514\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 19ms/step - accuracy: 0.8548 - loss: 0.4228 - val_accuracy: 0.8107 - val_loss: 0.5752 - learning_rate: 0.0010\n",
      "Test Accuracy:  0.8107094168663025\n"
     ]
    }
   ],
   "source": [
    "#StandardScaler로 \n",
    "\n",
    "pre_trained_models = ['sentence-transformers/xlm-r-100langs-bert-base-nli-stsb-mean-tokens',\n",
    "'sentence-transformers/multi-qa-distilbert-cos-v1',\n",
    "'jhgan/ko-sroberta-multitask',\n",
    "'all-distilroberta-v1',\n",
    "'jhgan/ko-sbert-multitask',\n",
    "'all-MiniLM-L12-v2', 'jhgan/ko-sroberta-sts']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "for i in pre_trained_models:\n",
    "    txt_embed = text_embedding(model_name = i)\n",
    "    X_embed = txt_embed.transform(X)\n",
    "   \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_embed,y, random_state=0,  test_size = 0.3, stratify = y)\n",
    "\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    X_train_scaled = np.expand_dims(X_train_scaled,axis =1)\n",
    "    X_test_scaled = np.expand_dims(X_test_scaled,axis =1)\n",
    "\n",
    "\n",
    "    model = second_model(X_train_scaled)\n",
    "    history=model.fit(X_train_scaled, y_train, batch_size=40, epochs=50, validation_data=(X_test_scaled, y_test), callbacks=[rlrp,mcp,es])\n",
    "\n",
    "    \n",
    "    test_loss, test_acc = model.evaluate(X_test_scaled, y_test, verbose=0)\n",
    "    print(\"Pre-trained Model: \", i)\n",
    "    print(\"Test Accuracy: \",test_acc)\n",
    "    \n",
    "#결과 \n",
    "#'sentence-transformers/multi-qa-distilbert-cos-v1'로 임베딩한 게 가장 좋다.(약 81.96%)\n",
    "# 'jhgan/ko-sbert-multitask'과 'jhgan/ko-sroberta-sts'도 나름대로 준수\n",
    "# 모델명 : model_06-0.8196.keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e1988d",
   "metadata": {},
   "source": [
    "### LSTM 모델(텍스트 임베딩)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "74e345e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m473/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4199 - loss: 0.4096\n",
      "Epoch 1: val_accuracy did not improve from 0.81958\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.4209 - loss: 0.4085 - val_accuracy: 0.5774 - val_loss: 0.2692 - learning_rate: 0.0010\n",
      "Epoch 2/30\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6253 - loss: 0.2450\n",
      "Epoch 2: val_accuracy did not improve from 0.81958\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6252 - loss: 0.2450 - val_accuracy: 0.6133 - val_loss: 0.2470 - learning_rate: 0.0010\n",
      "Epoch 3/30\n",
      "\u001b[1m458/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6828 - loss: 0.2110\n",
      "Epoch 3: val_accuracy did not improve from 0.81958\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6826 - loss: 0.2111 - val_accuracy: 0.6182 - val_loss: 0.2405 - learning_rate: 0.0010\n",
      "Epoch 4/30\n",
      "\u001b[1m471/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7158 - loss: 0.1911\n",
      "Epoch 4: val_accuracy did not improve from 0.81958\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7157 - loss: 0.1911 - val_accuracy: 0.6352 - val_loss: 0.2400 - learning_rate: 0.0010\n",
      "Epoch 5/30\n",
      "\u001b[1m478/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7549 - loss: 0.1688\n",
      "Epoch 5: val_accuracy did not improve from 0.81958\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7549 - loss: 0.1688 - val_accuracy: 0.6251 - val_loss: 0.2467 - learning_rate: 0.0010\n",
      "Pre-trained Model:  jhgan/ko-sroberta-sts\n",
      "Test Accuracy:  0.6230104565620422\n"
     ]
    }
   ],
   "source": [
    "# txt_embed = text_embedding(model_name = 'sentence-transformers/multi-qa-distilbert-cos-v1') 한 번 추출했으니까 그냥\n",
    "# X_embed = txt_embed.transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_embed, y, random_state=0, stratify = y, test_size = 0.3)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled  = scaler.transform(X_test)\n",
    "\n",
    "X_train_scaled = np.expand_dims(X_train_scaled,axis =1)\n",
    "X_test_scaled = np.expand_dims(X_test_scaled,axis =1)\n",
    "\n",
    "model = lstm_model(X_train_scaled)\n",
    "\n",
    "history = model.fit(X_train_scaled,y_train,\n",
    "               validation_split = 0.3,\n",
    "               epochs=30,\n",
    "               batch_size=30,callbacks=[rlrp,mcp,es])\n",
    "\n",
    "\n",
    "test_loss, test_acc = model.evaluate(X_test_scaled, y_test, verbose=0)\n",
    "print(\"Pre-trained Model: \", i)\n",
    "print(\"Test Accuracy: \",test_acc)\n",
    "\n",
    "#63퍼가 최대"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a76495",
   "metadata": {},
   "source": [
    "### SVC(텍스트 임베딩)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f80ec4c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "첫 번째 샘플의 클래스별 확률: [0.04770128 0.00425071 0.5767003  0.00182524 0.1100945  0.22532101\n",
      " 0.03410696]\n",
      "정확도 : 0.7137335152341974\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['svm_model.pkl']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# txt_embed = text_embedding(model_name = 'sentence-transformers/multi-qa-distilbert-cos-v1') #이미 위에서 추출한 거 있으니까 그냥 그거 쓴다.\n",
    "# X_embed = txt_embed.transform(X) 이것도\n",
    "\n",
    "X_train, X_test, y_train,y_test =train_test_split(X_embed,train_csv['감정'],random_state=5,stratify=train_csv['감정'],test_size=0.3)\n",
    "#MinMAx Scaler을 이용한 특징 벡터 전처리\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# 레이블 인코딩\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "\n",
    "\n",
    "#분류기 커널 설정\n",
    "clf = SVC(C=100, kernel='rbf', probability=True)\n",
    "#분류기 학습\n",
    "clf.fit(X_train_scaled, y_train_encoded )\n",
    "#각 row의 클래스별 확률을 구하기\n",
    "probabilities = clf.predict_proba(X_test_scaled)\n",
    "print(\"첫 번째 샘플의 클래스별 확률:\", probabilities[0])\n",
    "#예측 결과\n",
    "y_pred = clf.predict(X_test_scaled)\n",
    "accuracy = accuracy_score(y_pred, y_test_encoded)\n",
    "    \n",
    "\n",
    "    \n",
    "print(\"정확도 :\", accuracy)\n",
    "\n",
    "\n",
    "joblib.dump(clf, 'svm_model.pkl')\n",
    "\n",
    "# 첫 번째 샘플의 클래스별 확률: [0.04770128 0.00425071 0.5767003  0.00182524 0.1100945  0.22532101\n",
    "#  0.03410696]\n",
    "# 정확도 : 0.7137335152341974\n",
    "# ['svm_model.pkl']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a5b996",
   "metadata": {},
   "source": [
    "## 결과 \n",
    "- 위에서 나온 model_06-0.8196.keras 모델 이용해서 앞으로 작업할 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31039a65",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
